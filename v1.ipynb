{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGULATORY OPS CHANGED TO 'Regulatory' - UPDATE IT in NEXT SITERISK RUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import datetime\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carvana_sql import SQLServer # type: ignore\n",
    "db_conn = SQLServer.connect('PEOPLEOPSPROD,1439')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E102068\\AppData\\Local\\Temp\\ipykernel_15872\\2098714686.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  odbcdf = pd.read_sql_query(odbcquery, odbcconn)\n"
     ]
    }
   ],
   "source": [
    "cnx_str = \"Driver={ODBC Driver 17 for SQL Server};Server=PEOPLEOPSPROD,1439;Database=PEOPLEOPS;Trusted_Connection=yes;\"\n",
    "cnx_str_app = \"Driver={ODBC Driver 17 for SQL Server};Server=dwhcar-l;Database=OpsGroup;Trusted_Connection=yes;\"\n",
    "\n",
    "import pyodbc\n",
    "odbcconn = pyodbc.connect(cnx_str)\n",
    "odbcconnops = pyodbc.connect(cnx_str_app)\n",
    "odbcquery = 'Select Top 10 * from PeopleOps.tenstreet.FactDriver'\n",
    "odbcdf = pd.read_sql_query(odbcquery, odbcconn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todays Date - Used in multiple SQL queries\n",
    "# Change the value of today if you'd like to run the code at a different time\n",
    "\n",
    "# date_today=pd.to_datetime('2024-03-01')\n",
    "\n",
    "date_today=pd.to_datetime(datetime.date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_today=pd.to_datetime('2024-04-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carvana_sql import Snowflake\n",
    "\n",
    "SnowflakeWarehouse = 'PEOPLEOPS_ANALYTICS'\n",
    "SnowflakeRole = 'PEOPLEOPS_ANALYTICS'\n",
    "SnowflakeEmail = 'anish.middela@carvana.com'\n",
    "SnowflakeDatabase = \"PEOPLEOPS_SANDBOX\"\n",
    "Snowflakeschema=\"SITERISK\"\n",
    "\n",
    "db_snowflake = Snowflake.connect(\n",
    "                username=SnowflakeEmail,                \n",
    "                role=SnowflakeRole,\n",
    "                warehouse=SnowflakeWarehouse)\n",
    "\n",
    "db_snowflake_write = Snowflake.connect(\n",
    "                username=SnowflakeEmail,                \n",
    "                role=SnowflakeRole,\n",
    "                warehouse=SnowflakeWarehouse,\n",
    "                database=SnowflakeDatabase,\n",
    "                schema= Snowflakeschema )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local CSV Pull\n",
    "\n",
    "# # Files to pull location demographic csv\n",
    "# location_path=\"Glint Reports\"\n",
    "\n",
    "# # Level 1 csv files\n",
    "# location_files= glob.glob(os.path.join(location_path, \"*\\*.csv\"))\n",
    "\n",
    "# # Loop over lvl 2 subdirectory csv files\n",
    "# #location_files= glob.glob(os.path.join(location_path, \"**\\*.csv\"), recursive= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netwrok csv pull\n",
    "network_location_path=\"X:\\People_Operations\\Secured\\Talent Analytics\\Anish Middela\\SiteRisk\"\n",
    "\n",
    "# Level 1 csv files\n",
    "network_location_files= glob.glob(os.path.join(network_location_path, \"**\\*.csv\"),recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\ADESA\\\\glint_Q1'24_ADESA.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\glint_Carvana_Q1'24_Logistics.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\glint_Carvana_Q1'24_Market Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\glint_Carvana_Q1'24_Post Production.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\glint_Carvana_Q1'24_Reconditioning.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\glint_Carvana_Q1'24_Regulatory Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\glint_Carvana_Q1'24_Wholesale Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\Overall\\\\glint_report_Q1'24_AllCostCentre.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\Overall\\\\glint_report_Q1'24_AllLocations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\Overall\\\\glint_report_Q1'24_Managers.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\ADESA\\\\glint_Q1'25_ADESA.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\Carvana\\\\glint_Carvana_Q1'25_Logistics.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\Carvana\\\\glint_Carvana_Q1'25_Market Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\Carvana\\\\glint_Carvana_Q1'25_Post Production.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\Carvana\\\\glint_Carvana_Q1'25_Reconditioning.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\Carvana\\\\glint_Carvana_Q1'25_Regulatory Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\Carvana\\\\glint_Carvana_Q1'25_Wholesale Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\ADESA\\\\glint_Q2'24_ADESA.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\Carvana\\\\glint_Carvana_Q2'24_Logistics.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\Carvana\\\\glint_Carvana_Q2'24_Market Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\Carvana\\\\glint_Carvana_Q2'24_Post Production.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\Carvana\\\\glint_Carvana_Q2'24_Reconditioning.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\Carvana\\\\glint_Carvana_Q2'24_Regulatory Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\Carvana\\\\glint_Carvana_Q2'24_Wholesale Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\ADESA\\\\glint_Q2'25_ADESA.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\Carvana\\\\glint_Carvana_Q2'25_Logistics.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\Carvana\\\\glint_Carvana_Q2'25_Market Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\Carvana\\\\glint_Carvana_Q2'25_Post Production.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\Carvana\\\\glint_Carvana_Q2'25_Reconditioning.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\Carvana\\\\glint_Carvana_Q2'25_Regulatory Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\Carvana\\\\glint_Carvana_Q2'25_Wholesale Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\ADESA\\\\glint_Q3'24_ADESA.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\Carvana\\\\glint_Carvana_Q3'24_Logistics.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\Carvana\\\\glint_Carvana_Q3'24_Market Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\Carvana\\\\glint_Carvana_Q3'24_Post Production.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\Carvana\\\\glint_Carvana_Q3'24_Reconditioning.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\Carvana\\\\glint_Carvana_Q3'24_Regulatory Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\Carvana\\\\glint_Carvana_Q3'24_Wholesale Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\ADESA\\\\glint_Q4'24_ADESA.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\Carvana\\\\glint_Carvana_Q4'24_Logistics.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\Carvana\\\\glint_Carvana_Q4'24_Market Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\Carvana\\\\glint_Carvana_Q4'24_Post Production.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\Carvana\\\\glint_Carvana_Q4'24_Reconditioning.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\Carvana\\\\glint_Carvana_Q4'24_Regulatory Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\Carvana\\\\glint_Carvana_Q4'24_Wholesale Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Injuries\\\\injuries_report_Q1'24.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Injuries\\\\injuries_report_Q1'25.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Injuries\\\\injuries_report_Q2'24.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Injuries\\\\injuries_report_Q3'24.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Injuries\\\\injuries_report_Q4'24.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Navex\\\\navex_Q1'25.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Navex\\\\navex_Q2'25.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Navex\\\\navex_Q3'25.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Peakon\\\\Peakon_Q3'25.csv\"]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_location_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "glint_files = []\n",
    "injury_files = []\n",
    "navex_files = []\n",
    "overall_files=[]\n",
    "peakon_files=[]\n",
    "\n",
    "\n",
    "for path in network_location_files:\n",
    "    if \"Overall\" in path:\n",
    "        overall_files.append(path)\n",
    "    elif \"Navex\" in path:\n",
    "        navex_files.append(path)\n",
    "    elif \"Peakon\" in path:\n",
    "        peakon_files.append(path)\n",
    "    elif \"Glint\" in path:\n",
    "        glint_files.append(path)\n",
    "    elif \"Injuries\" in path:\n",
    "        injury_files.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files=os.listdir(\"C:/Users/E102068/Desktop/SiteRisk Dashboard/Glint Reports/Q1_24\")\n",
    "\n",
    "# # Files with overall data\n",
    "# main_path=\"Glint Reports\\Q1_24\\Overall\"\n",
    "\n",
    "# main_files= glob.glob(main_path+\"\\*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Navex\\\\navex_Q1'25.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Navex\\\\navex_Q2'25.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Navex\\\\navex_Q3'25.csv\"]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navex_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\ADESA\\\\glint_Q1'24_ADESA.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\glint_Carvana_Q1'24_Logistics.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\glint_Carvana_Q1'24_Market Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\glint_Carvana_Q1'24_Post Production.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\glint_Carvana_Q1'24_Reconditioning.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\glint_Carvana_Q1'24_Regulatory Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'24\\\\Carvana\\\\glint_Carvana_Q1'24_Wholesale Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\ADESA\\\\glint_Q1'25_ADESA.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\Carvana\\\\glint_Carvana_Q1'25_Logistics.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\Carvana\\\\glint_Carvana_Q1'25_Market Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\Carvana\\\\glint_Carvana_Q1'25_Post Production.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\Carvana\\\\glint_Carvana_Q1'25_Reconditioning.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\Carvana\\\\glint_Carvana_Q1'25_Regulatory Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q1'25\\\\Carvana\\\\glint_Carvana_Q1'25_Wholesale Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\ADESA\\\\glint_Q2'24_ADESA.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\Carvana\\\\glint_Carvana_Q2'24_Logistics.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\Carvana\\\\glint_Carvana_Q2'24_Market Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\Carvana\\\\glint_Carvana_Q2'24_Post Production.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\Carvana\\\\glint_Carvana_Q2'24_Reconditioning.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\Carvana\\\\glint_Carvana_Q2'24_Regulatory Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'24\\\\Carvana\\\\glint_Carvana_Q2'24_Wholesale Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\ADESA\\\\glint_Q2'25_ADESA.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\Carvana\\\\glint_Carvana_Q2'25_Logistics.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\Carvana\\\\glint_Carvana_Q2'25_Market Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\Carvana\\\\glint_Carvana_Q2'25_Post Production.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\Carvana\\\\glint_Carvana_Q2'25_Reconditioning.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\Carvana\\\\glint_Carvana_Q2'25_Regulatory Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q2'25\\\\Carvana\\\\glint_Carvana_Q2'25_Wholesale Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\ADESA\\\\glint_Q3'24_ADESA.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\Carvana\\\\glint_Carvana_Q3'24_Logistics.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\Carvana\\\\glint_Carvana_Q3'24_Market Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\Carvana\\\\glint_Carvana_Q3'24_Post Production.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\Carvana\\\\glint_Carvana_Q3'24_Reconditioning.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\Carvana\\\\glint_Carvana_Q3'24_Regulatory Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q3'24\\\\Carvana\\\\glint_Carvana_Q3'24_Wholesale Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\ADESA\\\\glint_Q4'24_ADESA.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\Carvana\\\\glint_Carvana_Q4'24_Logistics.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\Carvana\\\\glint_Carvana_Q4'24_Market Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\Carvana\\\\glint_Carvana_Q4'24_Post Production.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\Carvana\\\\glint_Carvana_Q4'24_Reconditioning.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\Carvana\\\\glint_Carvana_Q4'24_Regulatory Operations.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Glint Reports\\\\Q4'24\\\\Carvana\\\\glint_Carvana_Q4'24_Wholesale Operations.csv\"]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glint_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df = pd.DataFrame()\n",
    "# Appending all the csv files into one df\n",
    "for file in glint_files:\n",
    "    df_temp=pd.read_csv(file)\n",
    "    df_temp['JobFamilyGroup']= file.split('_')[-1].split('.')[0]\n",
    "    df_temp['Quarter']=file.split('_')[-2]\n",
    "\n",
    "    location_df=pd.concat([location_df,df_temp],ignore_index=True)\n",
    "\n",
    "    #df_temp['Quarter']=file.split('\\\\')[1] #Used this for Local Located files rather than network\n",
    "        # filename=file.split('_')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only neccesary columns\n",
    "location_df=location_df.iloc[:,[0,5,6,15,16]]\n",
    "\n",
    "# Rename\n",
    "location_df= location_df.rename(columns={location_df.columns[1]:'Score',location_df.columns[2]:'eSat Change'})\n",
    "\n",
    "# Filter out Location ==ALL\n",
    "location_df = location_df[~(location_df['Location'] == 'All')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Score' column to numeric, errors='coerce' will replace non-numeric values with NaN\n",
    "location_df['Score'] = pd.to_numeric(location_df['Score'], errors='coerce')\n",
    "location_df['eSat Change'] = pd.to_numeric(location_df['eSat Change'], errors='coerce')\n",
    "\n",
    "# Fill na ==0\n",
    "location_df=location_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Peakon\\\\Peakon_Q3'25.csv\"]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peakon_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peakon Data Pull\n",
    "peakon_df = pd.DataFrame()\n",
    "# Appending all the csv files into one df\n",
    "for file in peakon_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['Quarter'] = file.split('_')[-1].split('.')[0]\n",
    "    peakon_df = pd.concat([peakon_df, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peakon Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Location', 'JobFamilyGroup', 'Segment', 'Participants',\n",
       "       'Participation_Percentage', 'Score', 'Quarter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peakon_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakon_df['JobFamilyGroup'] = np.where(peakon_df['JobFamilyGroup'].str.contains('ADESA'), 'ADESA',peakon_df['JobFamilyGroup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakon_df['Employee_Size_Peakon'] = peakon_df['Participants']/peakon_df['Participation_Percentage']\n",
    "peakon_df['Employee_Size_Peakon'] = peakon_df['Employee_Size_Peakon'].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakon_df = peakon_df[['Location','JobFamilyGroup','Participants','Employee_Size_Peakon','Score','Quarter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty columns in location_df for merging later\n",
    "location_df['Participants']=None\n",
    "location_df['Employee_Size_Peakon']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df=location_df[['Location','JobFamilyGroup','Participants','Employee_Size_Peakon','Score','Quarter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df = pd.concat([location_df, peakon_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Quarter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "475b195e-108e-4034-9feb-4c54e64cf576",
       "rows": [
        [
         "Q3'25",
         "424"
        ],
        [
         "Q2'24",
         "417"
        ],
        [
         "Q3'24",
         "415"
        ],
        [
         "Q1'25",
         "405"
        ],
        [
         "Q2'25",
         "405"
        ],
        [
         "Q1'24",
         "400"
        ],
        [
         "Q4'24",
         "398"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 7
       }
      },
      "text/plain": [
       "Quarter\n",
       "Q3'25    424\n",
       "Q2'24    417\n",
       "Q3'24    415\n",
       "Q1'25    405\n",
       "Q2'25    405\n",
       "Q1'24    400\n",
       "Q4'24    398\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df['Quarter'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary JobFamilyGroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_JobFamilyGroups= location_df['JobFamilyGroup'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injuries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old Logic\n",
    "# injury_path=(\"Injuries\")\n",
    "\n",
    "# injury_files= glob.glob(os.path.join(injury_path, \"*.csv\"))\n",
    "\n",
    "# injuries_df= glob.glob(injury_path+'\\*.csv')\n",
    "# injuries_df=pd.read_csv(\"C:/Users/E102068/Desktop/SiteRisk Dashboard/Injuries/injuries_report_Q1'24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Injuries\\\\injuries_report_Q1'24.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Injuries\\\\injuries_report_Q1'25.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Injuries\\\\injuries_report_Q2'24.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Injuries\\\\injuries_report_Q3'24.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Injuries\\\\injuries_report_Q4'24.csv\"]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injury_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_df_main= pd.DataFrame()\n",
    "\n",
    "# Appending all the csv files into one DataFrame\n",
    "for file in injury_files:\n",
    "    df_temp_injury = pd.read_csv(file)\n",
    "\n",
    "\n",
    "    # Strip leading and trailing spaces from column names\n",
    "    df_temp_injury.columns = df_temp_injury.columns.str.strip()\n",
    "\n",
    "\n",
    "    # Add Quarter information\n",
    "    df_temp_injury['Quarter'] = file.split('_')[-1].split('.')[0]\n",
    "\n",
    "\n",
    "    # Concatenate to main DataFrame\n",
    "    injury_df_main = pd.concat([injury_df_main, df_temp_injury], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://carvana.okta.com/app/snowflake/exkhr8majsTrZPBMF1t7/sso/saml?SAMLRequest=jVJdc9owEPwrHvXZlm1CCRpMxjGlIR8NDaYz5U3YMijIkqOTsfn3lfnopA%2FJ9E1z2r3du73RTVsKZ880cCUjFHg%2BcpjMVM7lJkLLdOpeIwcMlTkVSrIIHRigm%2FEIaCkqEtdmK1%2FYW83AOLaRBNJ9RKjWkigKHIikJQNiMrKInx5J6PmEAjBtrBw6U3LgVmtrTEUwbprGa3qe0hsc%2Br6P%2FSG2qA7yBb2TqD7XqLQyKlPiQmntTB9IBNi%2F6iQswirMz8RbLk8r%2BExlfQIBuUvTuTt%2FXqTIiS%2FTJUpCXTK9YHrPM7Z8eTwZAOvgIY6vhr2w54FUTSHojmWqrGpjm3n2hQuWY6E23K5oNolQteN5KRbt5qce3BfLdXl4bZNv8f0qqxP6u9gu2PDuOVXN%2Fvv67SHJMuT8ugQadoHOAGo2k12Mxpb8sO8Goev309AnQZ8EX71gOFghZ2Jj5JKaI%2FPiNaN6TyX11M7QozlaVfivb8za3VZfl%2FQVUr2a3z5NAzPAAAp3KaHToZCjAT3%2Bz%2FFH%2BD3pfGo%2F7PZnk7kSPDs4U6VLaj4OJ%2FCCY4XnbnGEElZSLuI81wzAhiSEahLNqLEXbXTNEB6fVP%2B96fEf&RelayState=ver%3A1-hint%3A12085845463584774-ETMsDgAAAZrwJ5DlABRBRVMvQ0JDL1BLQ1M1UGFkZGluZwEAABAAEPqzcD2NMfnMo1suOJXGbYMAAACQe%2BmL35aZxs%2FANAS4QiH0mr2KBeHpGI6YTNWivceuqGfCRkiGRYFJrX7z%2F%2FiX3HgWsDMVKu9YtHbQlGDBUPK4Jjn9pUR2mbFiW7NHeB%2FpBv9MKDvN1MKOhLijKD3Ohd0tQWNGezP6dXo%2FEOFI0ITNizgIZmynXe%2BTb2EXzJrg07bQeNXoHG0j1oNTkI8CzMyrABSv04xnea1FX6273RzE%2BcY%2Bc97YLA%3D%3D to authenticate...\n"
     ]
    }
   ],
   "source": [
    "snowflake_pull_df = db_snowflake.execute(\n",
    "    \"\"\"\n",
    "SELECT CLAIM_NUMBER as CASE_NUMBER,\n",
    "       OCCURRENCE_NUMBER,\n",
    "       STATUS,\n",
    "       OCCURRED_DAY,\n",
    "       C_FIRSTDAYOFMONTHDATE,\n",
    "       LOCATION_NAME as WORK_LOCATION,\n",
    "       EMPLOYEE_ID_C as EMPLOYEE_ID,\n",
    "       TITLE as JOB_PROFILE,\n",
    "       DEPARTMENT,\n",
    "       JOB_FAMILY_GROUP,\n",
    "       JOB_FAMILY,\n",
    "       BODY_PART as BODYPART2,\n",
    "       DATE_TRUNC('QUARTER', OCCURRED_DAY) AS DATE_QUARTER,\n",
    "       CASE\n",
    "        WHEN DATE_QUARTER = '2025-04-01' THEN 'Q2''25'\n",
    "        WHEN DATE_QUARTER = '2025-07-01' THEN 'Q3''25'\n",
    "        END as Quarter\n",
    "FROM CARLEGAL.WC_INJURY.WC_CLAIMS_INPUT\n",
    "WHERE OCCURRED_DAY >= '2025-04-01' \n",
    "AND OCCURRED_DAY<'2025-10-01'\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_pull_df= snowflake_pull_df.rename(columns={\n",
    "    'QUARTER': 'Quarter',\n",
    "    'JOB_FAMILY_GROUP': 'JobFamilyGroup',\n",
    "    'JOB_PROFILE': 'JobProfile', \n",
    "    'JOB_FAMILY': 'JobFamily'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_df_main = pd.concat([injury_df_main, snowflake_pull_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Quarter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "6cfe9b38-a1af-45d8-b023-6eb5ae6c883c",
       "rows": [
        [
         "Q1'24",
         "346"
        ],
        [
         "Q1'25",
         "534"
        ],
        [
         "Q2'24",
         "398"
        ],
        [
         "Q2'25",
         "497"
        ],
        [
         "Q3'24",
         "447"
        ],
        [
         "Q3'25",
         "553"
        ],
        [
         "Q4'24",
         "419"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 7
       }
      },
      "text/plain": [
       "Quarter\n",
       "Q1'24    346\n",
       "Q1'25    534\n",
       "Q2'24    398\n",
       "Q2'25    497\n",
       "Q3'24    447\n",
       "Q3'25    553\n",
       "Q4'24    419\n",
       "dtype: int64"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injury_df_main.groupby('Quarter').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'RECONDITIONING', 'MARKET_OPERATIONS', 'JOB_FAMILY-3-381',\n",
       "       'POST_PRODUCTION', 'LOGISTICS', 'ACCOUNTING', 'JOB_FAMILY-3-379',\n",
       "       'JOB_FAMILY-3-380', 'JOB_FAMILY-3-382', 'JOB_FAMILY-3-383',\n",
       "       'Operations', 'SAFE_AND_SECURE', 'JOB_FAMILY-3-375', 'INVENTORY',\n",
       "       'REGULATORY_OPERATIONS', 'Reconditioning', 'Market Operations',\n",
       "       'Post Production', 'Logistics', 'Reconditioning Services (adesa)',\n",
       "       'Safe And Secure', 'Operations (adesa)', 'Regulatory Operations',\n",
       "       'Legal', 'Wholesale Operations', 'Sell To Carvana',\n",
       "       'Safe And Secure (adesa)', 'Technology Services', 'Verification',\n",
       "       'Sales (adesa)', 'Customer Service Group (adesa)',\n",
       "       'Customer Experience', 'Engineering', 'Treasury Operations',\n",
       "       'People Operations', 'Dealership', 'JOB_FAMILY-3-470',\n",
       "       'JOB_FAMILY-3-494', 'CUSTOMER_EXPERIENCE', 'WHOLESALE_OPERATIONS',\n",
       "       'JOB_FAMILY-3-451', 'JOB_FAMILY-3-471', 'JOB_FAMILY-3-500',\n",
       "       'STC_CUSTOMER_CARE', 'TECHNOLOGY_SERVICES', 'VERIFICATION',\n",
       "       'Infrastructure_Development', 'Auction', 'Transportation',\n",
       "       'Photobooth', 'Body Shop', 'Inventory', 'Mechanical',\n",
       "       'Maintenance', 'Detail', 'Office Operations', 'Registration', None,\n",
       "       'Marketplace', 'Central Operations (adesa)', 'Finance (adesa)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injury_df_main['JobFamilyGroup'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the 'JobFamilyGroup' column\n",
    "injury_df_main['JobFamilyGroup'] = injury_df_main['JobFamilyGroup'].apply(\n",
    "    lambda x: x.upper().replace(' ', '_') if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull JobProfile Detail from workday - TABLE EMPLOYEE HISTORY\n",
    "JobFamily_df = db_snowflake.execute(\"\"\"\n",
    "                             \n",
    "SELECT Distinct JOB_PROFILE,JOB_FAMILY_GROUP \n",
    "FROM PEOPLEOPS_SANDBOX.DEV.WORKDAY_EMPLOYEE_LINEAGE\n",
    "WHERE COMPANY NOT like '%ADESA%'\n",
    "AND JOB_FAMILY_GROUP NOT like '%ADESA%';\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobFamily_df=JobFamily_df.rename(columns={'JOB_PROFILE':'JobProfile','JOB_FAMILY_GROUP':'JobFamilyGroup'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging with Workday Jobfamily to get more accurate information\n",
    "injury_df_main= pd.merge(injury_df_main,JobFamily_df, how='left', on='JobProfile')\n",
    "\n",
    "# injury_df_check= pd.merge(injury_df,JobFamily_df, how='left', left_on='JobProfile',right_on='JobProfileName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_empl= db_snowflake.execute(\"\"\"\n",
    "\n",
    "WITH RankedEmployees AS (\n",
    "    SELECT \n",
    "        DATE_DAY, \n",
    "        EMPLOYEE_ID, \n",
    "        LOCATION,\n",
    "        ROW_NUMBER() OVER (PARTITION BY EMPLOYEE_ID ORDER BY DATE_DAY DESC) as rn\n",
    "    FROM \n",
    "        PEOPLEOPS_SANDBOX.DEV.WORKDAY_EMPLOYEE_LINEAGE\n",
    "    WHERE \n",
    "        LOCATION IS NOT NULL\n",
    ")\n",
    "\n",
    "SELECT  \n",
    "    EMPLOYEE_ID, \n",
    "    LOCATION                   \n",
    "FROM \n",
    "    RankedEmployees\n",
    "WHERE \n",
    "    rn = 1\n",
    "ORDER BY \n",
    "    EMPLOYEE_ID;\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_empl['EMPLOYEE_ID']=distinct_empl['EMPLOYEE_ID'].astype(int)\n",
    "injury_df_main['EMPLOYEE_ID'] = injury_df_main['EMPLOYEE_ID'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_df_main=pd.merge(injury_df_main,distinct_empl,on='EMPLOYEE_ID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_df_main['WORK_LOCATION']= np.where(injury_df_main['LOCATION'].isna(),injury_df_main['WORK_LOCATION'],injury_df_main['LOCATION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADESA', 'Logistics', 'Market Operations', 'Post Production', 'Reconditioning', 'Regulatory Operations', 'Wholesale Operations', 'Safe and Secure', 'Dealership', 'Engineering', 'Brand', 'Product Management', 'Marketplace', 'Technology Services', 'Titles', 'Customer Experience', 'Verification', 'Sell to Carvana', 'People Operations', 'Analytics', 'Legal', 'Accounting', 'Inventory', 'Treasury Operations', 'Finance', 'Infrastructure Development', 'Special Projects', 'Ancillary Products', 'Quantitative Marketing']\n",
      "[nan 'RECONDITIONING' 'MARKET_OPERATIONS' 'JOB_FAMILY-3-381'\n",
      " 'POST_PRODUCTION' 'LOGISTICS' 'ACCOUNTING' 'JOB_FAMILY-3-379'\n",
      " 'JOB_FAMILY-3-380' 'JOB_FAMILY-3-382' 'JOB_FAMILY-3-383' 'OPERATIONS'\n",
      " 'SAFE_AND_SECURE' 'JOB_FAMILY-3-375' 'INVENTORY' 'REGULATORY_OPERATIONS'\n",
      " 'RECONDITIONING_SERVICES_(ADESA)' 'OPERATIONS_(ADESA)' 'LEGAL'\n",
      " 'WHOLESALE_OPERATIONS' 'SELL_TO_CARVANA' 'SAFE_AND_SECURE_(ADESA)'\n",
      " 'TECHNOLOGY_SERVICES' 'VERIFICATION' 'SALES_(ADESA)'\n",
      " 'CUSTOMER_SERVICE_GROUP_(ADESA)' 'CUSTOMER_EXPERIENCE' 'ENGINEERING'\n",
      " 'TREASURY_OPERATIONS' 'PEOPLE_OPERATIONS' 'DEALERSHIP' 'JOB_FAMILY-3-470'\n",
      " 'JOB_FAMILY-3-494' 'JOB_FAMILY-3-451' 'JOB_FAMILY-3-471'\n",
      " 'JOB_FAMILY-3-500' 'STC_CUSTOMER_CARE' 'INFRASTRUCTURE_DEVELOPMENT'\n",
      " 'AUCTION' 'TRANSPORTATION' 'PHOTOBOOTH' 'BODY_SHOP' 'MECHANICAL'\n",
      " 'MAINTENANCE' 'DETAIL' 'OFFICE_OPERATIONS' 'REGISTRATION' None\n",
      " 'MARKETPLACE' 'CENTRAL_OPERATIONS_(ADESA)' 'FINANCE_(ADESA)']\n"
     ]
    }
   ],
   "source": [
    "print(necessary_JobFamilyGroups)\n",
    "print(injury_df_main['JobFamilyGroup_x'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column\n",
    "injury_df_main=injury_df_main.rename(columns={'JobFamilyGroup_y':'JobFamilyGroup'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Wherever their are NA then pointing it to Company\n",
    "injury_df_main['JobFamilyGroup'] = np.where(injury_df_main['JobFamilyGroup'].isna(),injury_df_main['JobFamilyGroup_x'],injury_df_main['JobFamilyGroup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Reconditioning', 'Market Operations', 'JOB_FAMILY-3-381',\n",
       "       'Post Production', 'Logistics', 'ACCOUNTING', 'JOB_FAMILY-3-379',\n",
       "       'JOB_FAMILY-3-380', 'JOB_FAMILY-3-382', 'JOB_FAMILY-3-383',\n",
       "       'OPERATIONS', 'SAFE_AND_SECURE', 'JOB_FAMILY-3-375',\n",
       "       'Regulatory Operations', 'Titles', 'Inventory', 'Safe and Secure',\n",
       "       'RECONDITIONING', 'MARKET_OPERATIONS', 'POST_PRODUCTION',\n",
       "       'RECONDITIONING_SERVICES_(ADESA)', 'LOGISTICS',\n",
       "       'OPERATIONS_(ADESA)', 'REGULATORY_OPERATIONS', 'Legal',\n",
       "       'Wholesale Operations', 'SELL_TO_CARVANA', 'WHOLESALE_OPERATIONS',\n",
       "       'SAFE_AND_SECURE_(ADESA)', 'TECHNOLOGY_SERVICES', 'Verification',\n",
       "       'SALES_(ADESA)', 'CUSTOMER_SERVICE_GROUP_(ADESA)', 'VERIFICATION',\n",
       "       'CUSTOMER_EXPERIENCE', 'ENGINEERING', 'TREASURY_OPERATIONS',\n",
       "       'People Operations', 'Dealership', 'Registration',\n",
       "       'JOB_FAMILY-3-470', 'JOB_FAMILY-3-494', 'Customer Experience',\n",
       "       'JOB_FAMILY-3-451', 'JOB_FAMILY-3-471', 'JOB_FAMILY-3-500',\n",
       "       'Sell to Carvana', 'Technology Services',\n",
       "       'Infrastructure Development', 'AUCTION', 'TRANSPORTATION',\n",
       "       'BODY_SHOP', 'INVENTORY', 'MECHANICAL', 'MAINTENANCE', 'DETAIL',\n",
       "       'OFFICE_OPERATIONS', 'Treasury Operations', None, 'Marketplace',\n",
       "       'CENTRAL_OPERATIONS_(ADESA)', 'FINANCE_(ADESA)'], dtype=object)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injury_df_main['JobFamilyGroup'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADESA', 'Logistics', 'Market Operations', 'Post Production', 'Reconditioning', 'Regulatory Operations', 'Wholesale Operations', 'Safe and Secure', 'Dealership', 'Engineering', 'Brand', 'Product Management', 'Marketplace', 'Technology Services', 'Titles', 'Customer Experience', 'Verification', 'Sell to Carvana', 'People Operations', 'Analytics', 'Legal', 'Accounting', 'Inventory', 'Treasury Operations', 'Finance', 'Infrastructure Development', 'Special Projects', 'Ancillary Products', 'Quantitative Marketing']\n"
     ]
    }
   ],
   "source": [
    "print(necessary_JobFamilyGroups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conditions for JobRole\n",
    "conditions = [\n",
    "    injury_df_main['JobFamilyGroup'].str.contains('ADESA|adesa', regex=True, na=False),\n",
    "    injury_df_main['JobFamilyGroup'].str.contains('RECONDITIONING|Inventory', regex=True, na=False),\n",
    "    injury_df_main['JobFamilyGroup'].str.contains('WHOLESALE_OPERATIONS', regex=True, na=False),\n",
    "    injury_df_main['JobFamilyGroup'].str.contains('POST_PRODUCTION', regex=True, na=False),\n",
    "    injury_df_main['JobFamilyGroup'].str.contains('REGULATORY_OPERATIONS', regex=True, na=False),\n",
    "    injury_df_main['JobFamilyGroup'].str.contains('LOGISTICS|TRANSPORTATION', regex=True, na=False),\n",
    "    injury_df_main['JobFamilyGroup'].str.contains('MARKET_OPERATIONS', regex=True, na=False),\n",
    "]\n",
    "\n",
    "\n",
    "# Define the corresponding JobRole values\n",
    "values = ['ADESA','Reconditioning','Wholesale Operations','Post Production','Regulatory Operations','Logistics','Market Operations']\n",
    "\n",
    "\n",
    "# Use np.select to create the JobRole column based on the conditions and values\n",
    "injury_df_main['JobFamilyGroup'] = np.select(conditions, values, injury_df_main['JobFamilyGroup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "injury_df_main['JobFamilyGroup'] = np.where(injury_df_main['JobFamilyGroup'].isna(),injury_df_main['COMPANY'],injury_df_main['JobFamilyGroup'])\n",
    "\n",
    "\n",
    "# Renaming Col\n",
    "injury_df_snowflake= injury_df_main.rename(columns={'WORK_LOCATION':'Location','BODYPART2':'Injuries'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowflake - Injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_df_snowflake = injury_df_snowflake[['Injuries','Location','JobFamilyGroup','JobProfile','Quarter','COMPANY','STATUS','CASE_NUMBER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Injuries",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "JobFamilyGroup",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "JobProfile",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Quarter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "COMPANY",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "STATUS",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CASE_NUMBER",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4415e427-5cf1-455f-ab2d-e4fd44e6120d",
       "rows": [
        [
         "0",
         "Back",
         "ADESA Riverside",
         "ADESA",
         null,
         "Q1'24",
         "ADESA",
         "submitted",
         "ADESA-7740"
        ],
        [
         "1",
         "Back",
         "Salt Lake",
         "ADESA",
         null,
         "Q1'24",
         "ADESA",
         "completed",
         "ADESA-7708"
        ],
        [
         "2",
         "['Shoulder(s)', 'Ankle']",
         "Los Angeles",
         "ADESA",
         null,
         "Q1'24",
         "ADESA",
         "completed",
         "ADESA-7668"
        ],
        [
         "3",
         "Knee",
         "ADESA Cincinnati",
         "ADESA",
         null,
         "Q1'24",
         "ADESA",
         "completed",
         "ADESA-7719"
        ],
        [
         "4",
         "Finger(s)",
         "Belton, MO",
         "ADESA",
         null,
         "Q1'24",
         "ADESA",
         "completed",
         "ADESA-7530"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Injuries</th>\n",
       "      <th>Location</th>\n",
       "      <th>JobFamilyGroup</th>\n",
       "      <th>JobProfile</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>CASE_NUMBER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Back</td>\n",
       "      <td>ADESA Riverside</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q1'24</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>submitted</td>\n",
       "      <td>ADESA-7740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Back</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q1'24</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>completed</td>\n",
       "      <td>ADESA-7708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Shoulder(s)', 'Ankle']</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q1'24</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>completed</td>\n",
       "      <td>ADESA-7668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Knee</td>\n",
       "      <td>ADESA Cincinnati</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q1'24</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>completed</td>\n",
       "      <td>ADESA-7719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finger(s)</td>\n",
       "      <td>Belton, MO</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q1'24</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>completed</td>\n",
       "      <td>ADESA-7530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Injuries          Location JobFamilyGroup JobProfile  \\\n",
       "0                      Back   ADESA Riverside          ADESA        NaN   \n",
       "1                      Back         Salt Lake          ADESA        NaN   \n",
       "2  ['Shoulder(s)', 'Ankle']       Los Angeles          ADESA        NaN   \n",
       "3                      Knee  ADESA Cincinnati          ADESA        NaN   \n",
       "4                 Finger(s)        Belton, MO          ADESA        NaN   \n",
       "\n",
       "  Quarter COMPANY     STATUS CASE_NUMBER  \n",
       "0   Q1'24   ADESA  submitted  ADESA-7740  \n",
       "1   Q1'24   ADESA  completed  ADESA-7708  \n",
       "2   Q1'24   ADESA  completed  ADESA-7668  \n",
       "3   Q1'24   ADESA  completed  ADESA-7719  \n",
       "4   Q1'24   ADESA  completed  ADESA-7530  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injury_df_snowflake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Quarter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9eb4e279-90d7-4e5f-bd8d-cc7a40578b3f",
       "rows": [
        [
         "Q1'24",
         "348"
        ],
        [
         "Q1'25",
         "535"
        ],
        [
         "Q2'24",
         "399"
        ],
        [
         "Q2'25",
         "502"
        ],
        [
         "Q3'24",
         "447"
        ],
        [
         "Q3'25",
         "555"
        ],
        [
         "Q4'24",
         "420"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 7
       }
      },
      "text/plain": [
       "Quarter\n",
       "Q1'24    348\n",
       "Q1'25    535\n",
       "Q2'24    399\n",
       "Q2'25    502\n",
       "Q3'24    447\n",
       "Q3'25    555\n",
       "Q4'24    420\n",
       "dtype: int64"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injury_df_snowflake.groupby('Quarter').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://carvana.okta.com/app/snowflake/exkhr8majsTrZPBMF1t7/sso/saml?SAMLRequest=jVLLcuIwEPwVl%2FaM5QcQogJSTiiyTiDxYpPK5iZsAVrbkqORMfx9ZB5b2UNSe1ONuqd7pmd4sy8La8cUcClGyLUdZDGRyoyLzQgtk2lngCzQVGS0kIKN0IEBuhkPgZZFRYJab8WCvdcMtGUaCSDtxwjVShBJgQMRtGRAdEriYD4jnu0QCsCUNnLoTMmAG62t1hXBuGkau%2FFtqTbYcxwHO9fYoFrID%2FRJovpeo1JSy1QWF8rezPSFhIudbithEEYhOhNvuTit4DuV1QkE5GeSRJ3oOU6QFVymu5MC6pKpmKkdT9lyMTsZAOPgMQi6177n2yBksy5ozlJZVrU2zWzzwmuW4UJuuFlROBmhKufZU3iI7w979z5ezR8Gu%2FTh%2BXeulq%2Bz9xQO%2FVVv3%2B%2F%2F8h%2B7i%2BjlNUiR9XIJ1GsDDQFqFoo2Rm1KjtfruF7H6SWeQ9we8fv24Mp7Q9bExMgF1UfmxWtK1Y4Kastc06M5WlX4r2%2FM9vlWDUr6BxL1Ft3Op66%2BwgAStymh06GQowE1%2Fs%2Fxh%2Fgz6XxqT2b74SSSBU8P1lSqkuqvw3Ft91jhWWd9hBJWUl4EWaYYgAmpKGRzpxjV5qK1qhnC45Pqvzc9%2FgA%3D&RelayState=ver%3A1-hint%3A12085845463584774-ETMsDgAAAZrwJ%2BGnABRBRVMvQ0JDL1BLQ1M1UGFkZGluZwEAABAAELSx%2BdoArCziI16qaQ5YD3cAAACQ81wIXYhxOgbBpulxDuEXGW960YGYoE3ejM1kEqqILMqaMblKCg0jb7isJqtPX6alItGF5ZE22dH7CjBDSQJD%2Be7ZPL4OS158Av078mUfQCaXRzAZJtgS78reSk77tXXzE%2BgrS%2BZuoe8vqBQUyhx%2BjbNYut1TLTjxj4w7w%2By77etWKe3wUtKtJZm0GrdOC9R%2BABTDsCpChvbKyV18CrYNkB7rivPnxA%3D%3D to authenticate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading data chunk num: 1: 100%|| 3206/3206 [00:00<00:00, 3772.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Uncomment when you want to run the script again\n",
    "# Write into Snowflake\n",
    "db_snowflake_write.insert('injuries',injury_df_snowflake,truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the existing table\n",
    "\n",
    "# db_snowflake_write.drop_table('Injuries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Table Creation\n",
    "\n",
    "# db_snowflake_write.create_table('Injuries',\n",
    "#                   {\n",
    "#                      'Injuries': ['VARCHAR(100)'], \n",
    "#                      'Location': ['VARCHAR(100)'], \n",
    "#                      'JobFamilyGroup': ['VARCHAR(100)'], \n",
    "#                      'JobProfile': ['VARCHAR(100)'],\n",
    "#                      'Quarter': ['VARCHAR(1000)'],\n",
    "#                      'Company': ['VARCHAR(100)'], \n",
    "#                      'STATUS': ['VARCHAR(100)'],\n",
    "#                      'CASE_NUMBER': ['VARCHAR(100)']\n",
    "#                   })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injury df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Only for necessary_JobFamilyGroups\n",
    "injury_df= injury_df_snowflake[injury_df_snowflake['JobFamilyGroup'].isin(necessary_JobFamilyGroups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of injuries at the Location-Org Combination\n",
    "injury_df = injury_df.groupby(['Location','JobFamilyGroup','Quarter']).agg('count').reset_index()\n",
    "\n",
    "# Final Injury df\n",
    "injury_df = injury_df[['Location', 'JobFamilyGroup','Quarter','Injuries']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging for Specific CostCentre\n",
    "main_df= pd.merge(location_df,injury_df, how='outer', on=['Location','JobFamilyGroup','Quarter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance PIPs/CARs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E102068\\AppData\\Local\\Temp\\ipykernel_15872\\4015103443.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  performance_sql_df = pd.read_sql_query(f\"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Performance for Last Quater\n",
    "performance_sql_df = pd.read_sql_query(f\"\"\"\n",
    "\n",
    "WITH cte AS (\n",
    "Select * FROM PeopleOps.workday.FactEmployeeReviews\n",
    "WHERE \n",
    "--DateInitiated >= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, '') - 1, 0)\n",
    "--AND DateInitiated < DATEADD(QUARTER, DATEDIFF(QUARTER, 0, ''), 0) \n",
    "--AND Status in ('In Progress','Successfully Completed','Rescinded') \n",
    "ReviewCategory in ('Corrective Action','Performance Improvement Plan')\n",
    "AND DateInitiated>='2024-01-01'\n",
    "AND DateInitiated < DATEADD(QUARTER, DATEDIFF(QUARTER, 0, GETDATE()), 0))\n",
    "\n",
    "SELECT c.EmployeeId,c.ReviewCategory,c.ReviewReason,c.ResultingActionRating,c.DateInitiated,c.Status,\n",
    "eh.StartDateTime,eh.EndDateTime,eh.JobFamilyGroup,eh.Company,eh.Location,\n",
    "CONCAT('Q', DATEPART(quarter,c.DateInitiated ), '''', RIGHT(DATEPART(year, c.DateInitiated), 2)) as Quarter   \n",
    "FROM cte c left join PeopleOps.workday.tblEmployeeHistory eh ON c.EmployeeId=eh.EmployeeId\n",
    "WHERE c.DateInitiated between eh.StartDateTime and eh.EndDateTime\n",
    "ORDER BY c.DateInitiated\n",
    "\n",
    "\"\"\",odbcconn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Launch in 2025\n",
    "\n",
    "performance_snowflake_base_df = db_snowflake.execute(\"\"\"\n",
    "with cte as (\n",
    "SELECT *\n",
    "FROM PEOPLEOPS.WORKDAY.EMPLOYEE_REVIEWS\n",
    "WHERE REVIEW_CATEGORY IN ('Corrective Action' ,'Performance Improvement Plan')\n",
    "AND DATE_INITIATED::DATE>='2024-01-01'\n",
    "AND DATE_INITIATED::DATE <= LAST_DAY(DATEADD(quarter, -1, DATE_TRUNC(quarter, CURRENT_DATE)),'quarter')\n",
    ")\n",
    "\n",
    "SELECT c.EMPLOYEE_ID\n",
    ",c.REVIEW_CATEGORY\n",
    ",c.REVIEW_REASON\n",
    ",c.RESULTING_ACTION_RATING\n",
    ",c.DATE_INITIATED\n",
    ",c.STATUS\n",
    ",eh.START_TIME\n",
    ",eh.END_TIME\n",
    ",eh.JOB_FAMILY_GROUP\n",
    ",eh.COMPANY\n",
    ",eh.LOCATION_NAME AS LOCATION\n",
    ",CONCAT('Q',DATE_PART('QUARTER',c.DATE_INITIATED),'''',RIGHT(DATE_PART('YEAR',C.DATE_INITIATED),2)) AS QUARTER\n",
    "FROM CTE c\n",
    "LEFT JOIN PEOPLEOPS.WORKDAY.VW_DIM_EMPLOYEE_HISTORY eh \n",
    "ON c.EMPLOYEE_ID = eh.EMPLOYEE_ID\n",
    "WHERE c.DATE_INITIATED BETWEEN eh.START_TIME AND eh.END_TIME\n",
    "ORDER BY C.DATE_INITIATED;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-12-05 00:00:00')"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In progress performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E102068\\AppData\\Local\\Temp\\ipykernel_15872\\3250169802.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  performance_inprogress_sql_df= pd.read_sql_query(f\"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Inprogress List with ToDO step COmpleted \n",
    "\n",
    "performance_inprogress_sql_df= pd.read_sql_query(f\"\"\"\n",
    "\n",
    "SELECT EmployeeId, Manager, ReviewTemplate, ProcessStatus as Status, ProcessInitiationDate as DateInitiated,\n",
    "Step,StepStatus,StepCompletedOn,StepCompletedBy \n",
    "FROM PeopleOps.workday.FactEmployeeReviewProcess\n",
    "WHERE \n",
    "--ProcessInitiationDate >= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, '{date_today}') - 1, 0)\n",
    "ProcessInitiationDate < DATEADD(QUARTER, DATEDIFF(QUARTER, 0, '{date_today}'), 0)\n",
    "AND ProcessInitiationDate>='2024-01-01'\n",
    "AND Step like '%To Do%' \n",
    "AND StepStatus = 'Step Completed'\n",
    "AND ProcessStatus ='In Progress'\n",
    "ORDER BY EmployeeId\n",
    "\n",
    "\"\"\",odbcconn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_inprogress_snowflake_base_df = db_snowflake.execute(f\"\"\"\n",
    "SELECT *\n",
    "FROM PEOPLEOPS.WORKDAY.VW_EMPLOYEE_REVIEW_PROCESS\n",
    "WHERE PROCESS_INITIATION_DATE  >='2024-01-01'\n",
    "AND PROCESS_INITIATION_DATE <= LAST_DAY(DATEADD(quarter, -1, DATE_TRUNC(quarter, CURRENT_DATE)),'quarter')\n",
    "AND STEP LIKE '%To Do%'\n",
    "AND STEP_STATUS ='Step Completed'\n",
    "AND PROCESS_STATUS = 'In Progress'\n",
    "ORDER BY PROCESS_INITIATION_DATE desc;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7040e077-dc65-4caf-91e9-5c3336cd0f27",
       "rows": [
        [
         "Successfully Completed",
         "37445"
        ],
        [
         "Canceled",
         "5094"
        ],
        [
         "In Progress",
         "3529"
        ],
        [
         "Rescinded",
         "80"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "Status\n",
       "Successfully Completed    37445\n",
       "Canceled                   5094\n",
       "In Progress                3529\n",
       "Rescinded                    80\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_sql_df.value_counts('Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Keys to check if the value exist in inprogess df (can be done using merge)\n",
    "\n",
    "performance_sql_df['key']=performance_sql_df['EmployeeId'].astype(str)+performance_sql_df['Status'].astype(str)\\\n",
    "    +performance_sql_df['DateInitiated'].astype(str)\n",
    "performance_inprogress_sql_df['key']=performance_inprogress_sql_df['EmployeeId'].astype(str)+performance_inprogress_sql_df['Status'].astype(str)\\\n",
    "    +performance_inprogress_sql_df['DateInitiated'].astype(str)\n",
    "\n",
    "# Finding rows that exist in inprogress and updating their status\n",
    "performance_sql_df.loc[performance_sql_df['key'].isin(performance_inprogress_sql_df['key']), 'Status'] = 'Successfully Completed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the key column\n",
    "performance_sql_df = performance_sql_df.drop(columns=['key'])\n",
    "performance_inprogress_sql_df = performance_inprogress_sql_df.drop(columns=['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d7946f70-afe7-40e0-857a-602cb4249473",
       "rows": [
        [
         "Successfully Completed",
         "39179"
        ],
        [
         "Canceled",
         "5094"
        ],
        [
         "In Progress",
         "1795"
        ],
        [
         "Rescinded",
         "80"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "Status\n",
       "Successfully Completed    39179\n",
       "Canceled                   5094\n",
       "In Progress                1795\n",
       "Rescinded                    80\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_sql_df.value_counts('Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADESA PIPs/CARs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Job Families in company ADESA as ADESA \n",
    "performance_sql_df['JobFamilyGroup'] = np.where(performance_sql_df['Company'].str.contains('ADESA'),\"ADESA\",performance_sql_df['JobFamilyGroup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neccessary Job Family Group\n",
    "# Filtering for siterisk costcentres\n",
    "performance_sql_df=performance_sql_df[performance_sql_df['JobFamilyGroup'].isin(necessary_JobFamilyGroups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "743fd5a5-6d5c-4259-a498-03817ff13e70",
       "rows": [
        [
         "Successfully Completed",
         "37401"
        ],
        [
         "Canceled",
         "4708"
        ],
        [
         "In Progress",
         "1761"
        ],
        [
         "Rescinded",
         "74"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "Status\n",
       "Successfully Completed    37401\n",
       "Canceled                   4708\n",
       "In Progress                1761\n",
       "Rescinded                    74\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_sql_df.value_counts('Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowflake - Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_snowflake_df = performance_sql_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EmployeeId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ReviewCategory",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ReviewReason",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ResultingActionRating",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DateInitiated",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "StartDateTime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "EndDateTime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "JobFamilyGroup",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Quarter",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5bfbea75-8664-4ee0-9f2c-6a42c841a5f0",
       "rows": [
        [
         "0",
         "94657",
         "Corrective Action",
         "Attendance (United States of America)",
         "Verbal Warning",
         "2024-01-02 03:18:05.688000",
         "Successfully Completed",
         "2023-12-24 01:17:00.013333",
         "2024-01-24 01:17:12.089000",
         "Reconditioning",
         "Carvana, LLC",
         "GA Winder IC",
         "Q1'24"
        ],
        [
         "1",
         "97414",
         "Corrective Action",
         "Attendance (United States of America)",
         "Termination",
         "2024-01-02 03:23:37.656000",
         "Successfully Completed",
         "2023-12-16 02:32:06.746666",
         "2024-01-03 09:16:49.509000",
         "Reconditioning",
         "Carvana, LLC",
         "NC Concord IC",
         "Q1'24"
        ],
        [
         "2",
         "99322",
         "Corrective Action",
         "Attendance (United States of America)",
         "Termination",
         "2024-01-02 05:02:06.346000",
         "Successfully Completed",
         "2023-12-25 01:16:53.613333",
         "2024-01-12 16:16:59.202333",
         "Logistics",
         "Carvana Logistics, LLC",
         "NJ Delanco IC",
         "Q1'24"
        ],
        [
         "3",
         "32950",
         "Corrective Action",
         "Attendance (United States of America)",
         "Written Warning",
         "2024-01-02 05:07:18.574000",
         "Successfully Completed",
         "2023-12-11 01:17:03.403333",
         "2024-01-11 01:17:02.609000",
         "Logistics",
         "Carvana Logistics, LLC",
         "AL Bessemer IC",
         "Q1'24"
        ],
        [
         "4",
         "97493",
         "Corrective Action",
         "Attendance (United States of America)",
         "Written Warning",
         "2024-01-02 05:19:05.466000",
         "Canceled",
         "2023-12-23 02:31:52.053333",
         "2024-01-04 10:30:27.369000",
         "ADESA",
         "ADESA US Auction LLC",
         "FL Orlando - Sanford",
         "Q1'24"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeId</th>\n",
       "      <th>ReviewCategory</th>\n",
       "      <th>ReviewReason</th>\n",
       "      <th>ResultingActionRating</th>\n",
       "      <th>DateInitiated</th>\n",
       "      <th>Status</th>\n",
       "      <th>StartDateTime</th>\n",
       "      <th>EndDateTime</th>\n",
       "      <th>JobFamilyGroup</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94657</td>\n",
       "      <td>Corrective Action</td>\n",
       "      <td>Attendance (United States of America)</td>\n",
       "      <td>Verbal Warning</td>\n",
       "      <td>2024-01-02 03:18:05.688</td>\n",
       "      <td>Successfully Completed</td>\n",
       "      <td>2023-12-24 01:17:00.013333</td>\n",
       "      <td>2024-01-24 01:17:12.089000</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>Carvana, LLC</td>\n",
       "      <td>GA Winder IC</td>\n",
       "      <td>Q1'24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97414</td>\n",
       "      <td>Corrective Action</td>\n",
       "      <td>Attendance (United States of America)</td>\n",
       "      <td>Termination</td>\n",
       "      <td>2024-01-02 03:23:37.656</td>\n",
       "      <td>Successfully Completed</td>\n",
       "      <td>2023-12-16 02:32:06.746666</td>\n",
       "      <td>2024-01-03 09:16:49.509000</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>Carvana, LLC</td>\n",
       "      <td>NC Concord IC</td>\n",
       "      <td>Q1'24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99322</td>\n",
       "      <td>Corrective Action</td>\n",
       "      <td>Attendance (United States of America)</td>\n",
       "      <td>Termination</td>\n",
       "      <td>2024-01-02 05:02:06.346</td>\n",
       "      <td>Successfully Completed</td>\n",
       "      <td>2023-12-25 01:16:53.613333</td>\n",
       "      <td>2024-01-12 16:16:59.202333</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>Carvana Logistics, LLC</td>\n",
       "      <td>NJ Delanco IC</td>\n",
       "      <td>Q1'24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32950</td>\n",
       "      <td>Corrective Action</td>\n",
       "      <td>Attendance (United States of America)</td>\n",
       "      <td>Written Warning</td>\n",
       "      <td>2024-01-02 05:07:18.574</td>\n",
       "      <td>Successfully Completed</td>\n",
       "      <td>2023-12-11 01:17:03.403333</td>\n",
       "      <td>2024-01-11 01:17:02.609000</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>Carvana Logistics, LLC</td>\n",
       "      <td>AL Bessemer IC</td>\n",
       "      <td>Q1'24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97493</td>\n",
       "      <td>Corrective Action</td>\n",
       "      <td>Attendance (United States of America)</td>\n",
       "      <td>Written Warning</td>\n",
       "      <td>2024-01-02 05:19:05.466</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>2023-12-23 02:31:52.053333</td>\n",
       "      <td>2024-01-04 10:30:27.369000</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>ADESA US Auction LLC</td>\n",
       "      <td>FL Orlando - Sanford</td>\n",
       "      <td>Q1'24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EmployeeId     ReviewCategory                           ReviewReason  \\\n",
       "0      94657  Corrective Action  Attendance (United States of America)   \n",
       "1      97414  Corrective Action  Attendance (United States of America)   \n",
       "2      99322  Corrective Action  Attendance (United States of America)   \n",
       "3      32950  Corrective Action  Attendance (United States of America)   \n",
       "4      97493  Corrective Action  Attendance (United States of America)   \n",
       "\n",
       "  ResultingActionRating           DateInitiated                  Status  \\\n",
       "0        Verbal Warning 2024-01-02 03:18:05.688  Successfully Completed   \n",
       "1           Termination 2024-01-02 03:23:37.656  Successfully Completed   \n",
       "2           Termination 2024-01-02 05:02:06.346  Successfully Completed   \n",
       "3       Written Warning 2024-01-02 05:07:18.574  Successfully Completed   \n",
       "4       Written Warning 2024-01-02 05:19:05.466                Canceled   \n",
       "\n",
       "               StartDateTime                EndDateTime  JobFamilyGroup  \\\n",
       "0 2023-12-24 01:17:00.013333 2024-01-24 01:17:12.089000  Reconditioning   \n",
       "1 2023-12-16 02:32:06.746666 2024-01-03 09:16:49.509000  Reconditioning   \n",
       "2 2023-12-25 01:16:53.613333 2024-01-12 16:16:59.202333       Logistics   \n",
       "3 2023-12-11 01:17:03.403333 2024-01-11 01:17:02.609000       Logistics   \n",
       "4 2023-12-23 02:31:52.053333 2024-01-04 10:30:27.369000           ADESA   \n",
       "\n",
       "                  Company              Location Quarter  \n",
       "0            Carvana, LLC          GA Winder IC   Q1'24  \n",
       "1            Carvana, LLC         NC Concord IC   Q1'24  \n",
       "2  Carvana Logistics, LLC         NJ Delanco IC   Q1'24  \n",
       "3  Carvana Logistics, LLC        AL Bessemer IC   Q1'24  \n",
       "4    ADESA US Auction LLC  FL Orlando - Sanford   Q1'24  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_snowflake_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Quarter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "89ac1725-c7ad-4f48-b270-f41461d327da",
       "rows": [
        [
         "Q1'24",
         "4083"
        ],
        [
         "Q1'25",
         "6981"
        ],
        [
         "Q2'24",
         "4588"
        ],
        [
         "Q2'25",
         "7465"
        ],
        [
         "Q3'24",
         "5491"
        ],
        [
         "Q3'25",
         "9728"
        ],
        [
         "Q4'24",
         "5608"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 7
       }
      },
      "text/plain": [
       "Quarter\n",
       "Q1'24    4083\n",
       "Q1'25    6981\n",
       "Q2'24    4588\n",
       "Q2'25    7465\n",
       "Q3'24    5491\n",
       "Q3'25    9728\n",
       "Q4'24    5608\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_snowflake_df.groupby('Quarter').size()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DateInitiated",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "StartDateTime",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "EndDateTime",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "46b84e8b-209f-4cf9-864f-c97306d9be87",
       "rows": [
        [
         "count",
         "43944",
         "43944",
         "43944"
        ],
        [
         "mean",
         "2025-01-05 02:48:23.706334720",
         "2024-12-25 02:04:45.908569088",
         "2025-01-13 14:23:04.902321920"
        ],
        [
         "min",
         "2024-01-02 03:18:05.688000",
         "2023-12-04 15:16:53.863333",
         "2024-01-02 11:17:57.979000"
        ],
        [
         "25%",
         "2024-08-08 07:28:09.929750016",
         "2024-07-28 00:17:08.053332992",
         "2024-08-16 12:31:16.968999936"
        ],
        [
         "50%",
         "2025-01-30 13:55:30.258000128",
         "2025-01-20 01:16:17.689999872",
         "2025-02-10 01:16:25.815665920"
        ],
        [
         "75%",
         "2025-06-12 13:17:24.823749888",
         "2025-06-02 00:15:57.603333120",
         "2025-06-24 10:16:00.962332928"
        ],
        [
         "max",
         "2025-09-30 23:00:59.044000",
         "2025-09-30 11:16:08.836666",
         "2025-10-29 00:17:09.075666"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateInitiated</th>\n",
       "      <th>StartDateTime</th>\n",
       "      <th>EndDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43944</td>\n",
       "      <td>43944</td>\n",
       "      <td>43944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2025-01-05 02:48:23.706334720</td>\n",
       "      <td>2024-12-25 02:04:45.908569088</td>\n",
       "      <td>2025-01-13 14:23:04.902321920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2024-01-02 03:18:05.688000</td>\n",
       "      <td>2023-12-04 15:16:53.863333</td>\n",
       "      <td>2024-01-02 11:17:57.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2024-08-08 07:28:09.929750016</td>\n",
       "      <td>2024-07-28 00:17:08.053332992</td>\n",
       "      <td>2024-08-16 12:31:16.968999936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2025-01-30 13:55:30.258000128</td>\n",
       "      <td>2025-01-20 01:16:17.689999872</td>\n",
       "      <td>2025-02-10 01:16:25.815665920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2025-06-12 13:17:24.823749888</td>\n",
       "      <td>2025-06-02 00:15:57.603333120</td>\n",
       "      <td>2025-06-24 10:16:00.962332928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025-09-30 23:00:59.044000</td>\n",
       "      <td>2025-09-30 11:16:08.836666</td>\n",
       "      <td>2025-10-29 00:17:09.075666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       DateInitiated                  StartDateTime  \\\n",
       "count                          43944                          43944   \n",
       "mean   2025-01-05 02:48:23.706334720  2024-12-25 02:04:45.908569088   \n",
       "min       2024-01-02 03:18:05.688000     2023-12-04 15:16:53.863333   \n",
       "25%    2024-08-08 07:28:09.929750016  2024-07-28 00:17:08.053332992   \n",
       "50%    2025-01-30 13:55:30.258000128  2025-01-20 01:16:17.689999872   \n",
       "75%    2025-06-12 13:17:24.823749888  2025-06-02 00:15:57.603333120   \n",
       "max       2025-09-30 23:00:59.044000     2025-09-30 11:16:08.836666   \n",
       "\n",
       "                         EndDateTime  \n",
       "count                          43944  \n",
       "mean   2025-01-13 14:23:04.902321920  \n",
       "min       2024-01-02 11:17:57.979000  \n",
       "25%    2024-08-16 12:31:16.968999936  \n",
       "50%    2025-02-10 01:16:25.815665920  \n",
       "75%    2025-06-24 10:16:00.962332928  \n",
       "max       2025-10-29 00:17:09.075666  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_snowflake_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading data chunk num: 1: 100%|| 43944/43944 [00:01<00:00, 36960.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment when you need to run it again\n",
    "# Write into Snowflake\n",
    "# db_snowflake_write.drop_table('Performance')\n",
    "# db_snowflake_write.dump('Performance',performance_snowflake_df)\n",
    "db_snowflake_write.insert('Performance',performance_snowflake_df,truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the existing table\n",
    "\n",
    "# db_snowflake_write.drop_table('Performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Performance Table Creation\n",
    "\n",
    "# db_snowflake_write.create_table('Performance',\n",
    "#                   {\n",
    "#                      'EmployeeId': ['INT','NOT NULL'],\n",
    "#                      'ReviewCategory': ['VARCHAR(1000)'], \n",
    "#                      'ReviewReason': ['VARCHAR(1000)'], \n",
    "#                      'ResultingActionRating': ['VARCHAR(1000)'],\n",
    "#                      'Status':['VARCHAR(1000)'],\n",
    "#                      'DateInitiated': ['TIMESTAMP_NTZ(9)'], \n",
    "#                      'StartDateTime': ['TIMESTAMP_NTZ(9)'],\n",
    "#                      'EndDateTime' : ['TIMESTAMP_NTZ(9)'],\n",
    "#                      'JobFamilyGroup': ['VARCHAR(1000)'],\n",
    "#                      'Company': ['VARCHAR(1000)'],\n",
    "#                      'Location': ['VARCHAR(1000)'],\n",
    "#                      'Quarter': ['VARCHAR(1000)']\n",
    "#                   })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df= db_snowflake.execute(\"\"\"\n",
    "\n",
    "SELECT * FROM PEOPLEOPS_SANDBOX.SITERISK.PERFORMANCE\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering only for Successfully completed\n",
    "performance_df=performance_df[performance_df['STATUS']=='Successfully Completed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "STATUS",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0d67c326-bbe0-4c9a-a702-42c4c8e1dd23",
       "rows": [
        [
         "Successfully Completed",
         "37401"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 1
       }
      },
      "text/plain": [
       "STATUS\n",
       "Successfully Completed    37401\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df.value_counts('STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Q1'24\", \"Q2'24\", \"Q3'24\", \"Q4'24\", \"Q1'25\", \"Q2'25\", \"Q3'25\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df['QUARTER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting neccesary columns\n",
    "# performance_df= performance_df.iloc[:,[0,1,-4,-2,-1]]\n",
    "performance_df= performance_df[['EMPLOYEEID','LOCATION','JOBFAMILYGROUP','QUARTER','REVIEWCATEGORY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of PIPs/Cars and Unique Employees\n",
    "performance_df= performance_df.groupby(['LOCATION','JOBFAMILYGROUP','QUARTER','REVIEWCATEGORY']).\\\n",
    "                                agg(Total_Count=('EMPLOYEEID','count'),EmployeesPIPs_CARs=('EMPLOYEEID','nunique')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37401"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df['Total_Count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to divide the PIPs/CARs\n",
    "performance_df= performance_df.pivot(index=['LOCATION','JOBFAMILYGROUP','QUARTER','EmployeesPIPs_CARs'],\\\n",
    "                                     columns=['REVIEWCATEGORY'],values='Total_Count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sum of all\n",
    "performance_df= performance_df.groupby(['LOCATION','JOBFAMILYGROUP','QUARTER']).agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall PIPs/CARs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling all NA with 0 for addition\n",
    "performance_df=performance_df.fillna(0)\n",
    "\n",
    "# Sum of ALL PIPs/CARs\n",
    "performance_df['PIPs & CARs']=performance_df['Performance Improvement Plan']\\\n",
    "                                    +performance_df['Corrective Action']\n",
    "\n",
    "# Rename\n",
    "performance_df=performance_df.rename(columns={'Performance Improvement Plan':'PIPs',\\\n",
    "                                              'Corrective Action':'CARs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37401.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df['PIPs & CARs'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Colmns\n",
    "performance_df=performance_df.rename(columns={'LOCATION':'Location','JOBFAMILYGROUP':'JobFamilyGroup','QUARTER':'Quarter'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge-Main Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=pd.merge(main_df,performance_df,on=['Location','Quarter','JobFamilyGroup'],how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "JobFamilyGroup",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Quarter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Injuries",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "EmployeesPIPs_CARs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CARs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PIPs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PIPs & CARs",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ff6aa38b-012c-4244-8d16-496f83aad3f8",
       "rows": [
        [
         "0",
         "11625 nino way mira loma ca 91752",
         "ADESA",
         null,
         "Q3'24",
         "1.0",
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "ADESA",
         "ADESA",
         null,
         "Q2'24",
         "1.0",
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "ADESA Cincinnati",
         "ADESA",
         null,
         "Q1'24",
         "1.0",
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "ADESA Riverside",
         "ADESA",
         null,
         "Q1'24",
         "1.0",
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "AL Bessemer IC",
         "Logistics",
         "71.0",
         "Q1'24",
         null,
         "24.0",
         "38.0",
         "0.0",
         "38.0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>JobFamilyGroup</th>\n",
       "      <th>Score</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Injuries</th>\n",
       "      <th>EmployeesPIPs_CARs</th>\n",
       "      <th>CARs</th>\n",
       "      <th>PIPs</th>\n",
       "      <th>PIPs &amp; CARs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11625 nino way mira loma ca 91752</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q3'24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADESA</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q2'24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADESA Cincinnati</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q1'24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADESA Riverside</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q1'24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL Bessemer IC</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Q1'24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Location JobFamilyGroup  Score Quarter  Injuries  \\\n",
       "0  11625 nino way mira loma ca 91752          ADESA    NaN   Q3'24       1.0   \n",
       "1                              ADESA          ADESA    NaN   Q2'24       1.0   \n",
       "2                   ADESA Cincinnati          ADESA    NaN   Q1'24       1.0   \n",
       "3                    ADESA Riverside          ADESA    NaN   Q1'24       1.0   \n",
       "4                     AL Bessemer IC      Logistics   71.0   Q1'24       NaN   \n",
       "\n",
       "   EmployeesPIPs_CARs  CARs  PIPs  PIPs & CARs  \n",
       "0                 NaN   NaN   NaN          NaN  \n",
       "1                 NaN   NaN   NaN          NaN  \n",
       "2                 NaN   NaN   NaN          NaN  \n",
       "3                 NaN   NaN   NaN          NaN  \n",
       "4                24.0  38.0   0.0         38.0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turnover/Attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNOWFLAKE USING WORKER LINEAGE\n",
    "\n",
    "\n",
    "# SELECT DISTINCT EmployeeId FROM PEOPLEOPS_SANDBOX.DEV.WORKDAY_EMPLOYEE_LINEAGE WHERE DATE='2024-01-01' AND DATA_TYPE='ACTIVE' AND EMPLOYEETYPE='Regular' AND WORKERSTATUS IN ('Active','On Leave');\n",
    "\n",
    "\n",
    "# Quarter_start_df = db_snowflake.execute(\"\"\"\n",
    "\n",
    "# SELECT wl.EMPLOYEEID, wl.date, wl.DATA_TYPE as Status, wl.employeename, wl.jobprofile, wl.costcenter as Organization, sd.location_name as Location,\n",
    "#     CONCAT('Q', DATE_PART('quarter', wl.Date), '''', RIGHT(DATE_PART('year', wl.Date), 2)) as Quarter\n",
    "# FROM PEOPLEOPS_SANDBOX.DEV.WORKDAY_EMPLOYEE_LINEAGE wl\n",
    "# LEFT JOIN SHARED.DW.DIM_EMPLOYEE sd \n",
    "#     on wl.employeeid = sd.employee_id_cv\n",
    "# WHERE wl.Date = DATEADD('quarter', -1, DATE_TRUNC('quarter', CURRENT_TIMESTAMP))\n",
    "#     AND wl.MATRIXORGANIZATION is not Null\n",
    "#     AND wl.data_type='ACTIVE'\n",
    "# ORDER BY wl.Date, wl.EMPLOYEEID;\n",
    "\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD TURNOVER LOGIC\n",
    "\n",
    "# Turnover_sql_df= db_conn.execute(\"\"\"\n",
    "\n",
    "# with active as \n",
    "# (\n",
    "# SELECT \n",
    "#     MIN(StartDateTime) as StartDateTime,\n",
    "#     MAX(EndDateTime) as EndDateTime,\n",
    "# \tFirstName, \n",
    "# \tLastName,\n",
    "#     EmployeeId\n",
    "# FROM \n",
    "#     PeopleOps.workday.tblEmployeeHistory\n",
    "# WHERE \n",
    "#     (StartDateTime <= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, '{date_today}'), 0) - 1 AND EndDateTime >= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, '{date_today}') - 1, 0))\n",
    "#     AND ActiveStatus = 1\n",
    "#     AND SSIS_IsDeleted = 0\n",
    "#     AND EmployeeType = 'Regular'\n",
    "# GROUP BY\n",
    "# \tFirstName, \n",
    "# \tLastName,\n",
    "#     EmployeeId\n",
    "# )\n",
    "\n",
    "# , terms as (\n",
    "# SELECT \n",
    "#      distinct EmployeeId,TerminationDate,\n",
    "# \t RANK() OVER(PARTITION BY EmployeeId ORDER BY TerminationDate) AS Ranking \n",
    "# FROM \n",
    "#     PeopleOps.workday.tblEmployeeHistory\n",
    "# WHERE \n",
    "# \tTerminationDate is Not Null AND\n",
    "#     (TerminationDate <= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, '{date_today}'), 0) - 1 AND TerminationDate >= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, '{date_today}') - 1, 0))\n",
    "\n",
    "# )\n",
    "\n",
    "# select a.EmployeeId,StartDateTime,EndDateTime,FirstName,LastName,TerminationDate,Ranking\n",
    "# from active a left join terms t on a.EmployeeId=t.EmployeeId\n",
    "# order by a.EmployeeId\n",
    "\n",
    "\n",
    "# \"\"\")\n",
    "# # If multiple term then we stop at enddatetime\n",
    "# Turnover_sql_df['EndDateTime']= np.where(Turnover_sql_df['TerminationDate'].isna(),Turnover_sql_df['EndDateTime'],Turnover_sql_df['TerminationDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active/Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turnover_sql_active= db_conn.execute(f\"\"\"\n",
    "\n",
    "# SELECT \n",
    "#     StartDateTime,\n",
    "#     EndDateTime,\n",
    "#     EmployeeId,\n",
    "#     JobFamilyGroup,\n",
    "#     Location\n",
    "# FROM \n",
    "#     PeopleOps.workday.tblEmployeeHistory\n",
    "# WHERE \n",
    "#     (StartDateTime <= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, '{date_today}'), 0) - 1 AND EndDateTime >= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, '{date_today}') - 1, 0))\n",
    "#     AND ActiveStatus = 1\n",
    "#     AND SSIS_IsDeleted = 0\n",
    "#     AND EmployeeType = 'Regular'\n",
    "# Order By \n",
    "# \tEmployeeId\n",
    "\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update the Quater based on when you are running****\n",
    "# active_emps= db_snowflake.execute(f\"\"\"\n",
    "\n",
    "\n",
    "# SELECT \n",
    "#     DATE_DAY as Date, \n",
    "#     EMPLOYEE_ID, \n",
    "#     JOB_FAMILY_GROUP, \n",
    "#     LOCATION, \n",
    "#     'Q3''24' as QUARTER\n",
    "# FROM \n",
    "#     PEOPLEOPS_SANDBOX.DEV.WORKDAY_EMPLOYEE_LINEAGE\n",
    "# WHERE \n",
    "#     DATA_TYPE = 'ACTIVE'\n",
    "#     AND EMPLOYEE_TYPE='Regular'\n",
    "#     AND DATE_DAY <= DATEADD(QUARTER, DATEDIFF(QUARTER, '2000-01-01', '{date_today}'), '2000-01-01') - INTERVAL '1 DAY'\n",
    "#     AND DATE_DAY >= DATEADD(QUARTER, DATEDIFF(QUARTER, '2000-01-01', '{date_today}') - 1, '2000-01-01')\n",
    "#     --AND JOB_FAMILY_GROUP IN {necessary_JobFamilyGroups}\n",
    "# ORDER BY \n",
    "#     DATE_DAY\n",
    "\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for neccessary jobfamily groups\n",
    "# active_emps=active_emps[active_emps['JOB_FAMILY_GROUP'].isin(necessary_JobFamilyGroups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_snowflake_write.drop_table('ACTIVE_EMPLOYEES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_snowflake_write.insert('ACTIVE_EMPLOYEES',active_emps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract only date\n",
    "# turnover_sql_active['StartDateTime']=turnover_sql_active['StartDateTime'].dt.date\n",
    "# turnover_sql_active['EndDateTime']=turnover_sql_active['EndDateTime'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Df to store all the dates active for each employee \n",
    "# turnover_expanded_data=[]\n",
    "\n",
    "# # Iterate over each row\n",
    "# for index, row in turnover_sql_active.iterrows():\n",
    "#     # Generate dates for all the dates between startdate and enddate\n",
    "#     dates_range= pd.date_range(start=row['StartDateTime'],end=row['EndDateTime'])\n",
    "\n",
    "#     for date in dates_range:\n",
    "#         turnover_expanded_data.append({\n",
    "#             'Date': date,\n",
    "#             'EmployeeId':row['EmployeeId'],\n",
    "#             'JobFamilyGroup':row['JobFamilyGroup'],\n",
    "#             'Location':row['Location']\n",
    "#        })\n",
    "\n",
    "# # Convert to data frame\n",
    "# turnover_expanded_df= pd.DataFrame(turnover_expanded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Building a date list to capture dynamically all the dates in last quarter\n",
    "# from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# # Define the start and end of the previous quarter\n",
    "# if date_today.month < 4:\n",
    "#     start = datetime.date(date_today.year - 1, 10, 1)\n",
    "#     end = datetime.date(date_today.year - 1, 12, 31)\n",
    "# elif date_today.month < 7:\n",
    "#     start = datetime.date(date_today.year, 1, 1)\n",
    "#     end = datetime.date(date_today.year, 3, 31)\n",
    "# elif date_today.month < 10:\n",
    "#     start = datetime.date(date_today.year, 4, 1)\n",
    "#     end = datetime.date(date_today.year, 6, 30)\n",
    "# else:\n",
    "#     start = datetime.date(date_today.year, 7, 1)\n",
    "#     end = datetime.date(date_today.year, 9, 30)\n",
    "\n",
    "\n",
    "# # Create list of dates within the previous quarter\n",
    "# last_quarter_date_list = [(start + datetime.timedelta(days=x)).isoformat() for x in range((end-start).days + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to remove dates where we have overlaping dates for each startdatetime and enddatetime\n",
    "# turnover_active_df = turnover_expanded_df.drop_duplicates()\n",
    "\n",
    "# # Filter for dates only in last quater\n",
    "# turnover_active_df = turnover_active_df[turnover_active_df['Date'].isin(last_quarter_date_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Terminations\n",
    "\n",
    "# turnover_sql_terms= db_conn.execute(f\"\"\"\n",
    "\n",
    "# SELECT \n",
    "#     distinct EmployeeId,\n",
    "#     CONCAT(FirstName,' ',LastName) as Name,\n",
    "#     JobFamilyGroup,\n",
    "#     Location,\n",
    "#     TerminationDate\n",
    "# FROM \n",
    "#     PeopleOps.workday.tblEmployeeHistory\n",
    "# WHERE \n",
    "# \tTerminationDate is Not Null \n",
    "#     AND SSIS_IsDeleted = 0\n",
    "#     AND EmployeeType = 'Regular'\n",
    "#     AND (TerminationDate <= DATEADD(QUARTER, DATEDIFF(QUARTER, 0,'{date_today}'), 0) - 1 \n",
    "#     AND TerminationDate >= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, '{date_today}') - 1, 0))\n",
    "# ORDER BY \n",
    "#     TerminationDate\n",
    "\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the Quater based on when you are running****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update the Quater based on when you are running****\n",
    "\n",
    "turnover_sql_terms= db_snowflake_write.execute(f\"\"\"\n",
    "\n",
    "SELECT \n",
    "    DATE_DAY as TerminationDate,\n",
    "    EMPLOYEE_ID,\n",
    "    EMPLOYEE_NAME as NAME,\n",
    "    CASE\n",
    "    WHEN JOB_FAMILY_GROUP like '%ADESA%' THEN 'ADESA'\n",
    "    ELSE JOB_FAMILY_GROUP\n",
    "    END as JOB_FAMILY_GROUP, \n",
    "    LOCATION, \n",
    "    CASE\n",
    "        WHEN DATE_QUARTER = '2024-01-01' THEN 'Q1''24'\n",
    "        WHEN DATE_QUARTER = '2024-04-01' THEN 'Q2''24'\n",
    "        WHEN DATE_QUARTER = '2024-07-01' THEN 'Q3''24'\n",
    "        WHEN DATE_QUARTER = '2024-10-01' THEN 'Q4''24'\n",
    "        WHEN DATE_QUARTER = '2025-01-01' THEN 'Q1''25'\n",
    "        WHEN DATE_QUARTER = '2025-04-01' THEN 'Q2''25'                                              \n",
    "        WHEN DATE_QUARTER = '2025-07-01' THEN 'Q3''25'                                              \n",
    "    END AS Quarter,\n",
    "FROM \n",
    "    PEOPLEOPS_SANDBOX.DEV.WORKDAY_EMPLOYEE_LINEAGE\n",
    "WHERE \n",
    "    DATA_TYPE = 'TERMINATED'\n",
    "    AND EMPLOYEE_TYPE='Regular'\n",
    "    AND DATE_DAY>='2024-01-01'\n",
    "ORDER BY \n",
    "    DATE_DAY\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to Date\n",
    "turnover_sql_terms['TERMINATIONDATE']=pd.to_datetime(turnover_sql_terms['TERMINATIONDATE'])\n",
    "\n",
    "# Neccesary JobFamilyGroups\n",
    "turnover_sql_terms=turnover_sql_terms[turnover_sql_terms['JOB_FAMILY_GROUP'].isin(necessary_JobFamilyGroups) & turnover_sql_terms['QUARTER'].notna()]\n",
    "\n",
    "# # Adding Quarter based on Date column\n",
    "# turnover_sql_terms['Quarter'] = turnover_sql_terms['TerminationDate'].dt.to_period(\"Q\")\n",
    "# turnover_sql_terms['Quarter'] = turnover_sql_terms['Quarter'].apply(lambda q: f\"{q.strftime('Q%q')}'{str(q.year)[2:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowflake - Terminated Emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Table\n",
    "# db_snowflake_write.create_table('TermEmployee',\n",
    "#                   {\n",
    "#                      'EmployeeId': ['INT','NOT NULL'],\n",
    "#                      'Name': ['VARCHAR(1000)'], \n",
    "#                      'JobFamilyGroup': ['VARCHAR(1000)'], \n",
    "#                      'Location': ['VARCHAR(1000)'],\n",
    "#                      'TerminationDate': ['TIMESTAMP_NTZ(9)'], \n",
    "#                      'Quarter': ['VARCHAR(1000)']\n",
    "#                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_snowflake_write.drop_table('TermEmployee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19827, 6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TERMINATIONDATE",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "EMPLOYEE_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "NAME",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "JOB_FAMILY_GROUP",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "LOCATION",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "QUARTER",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ab3ebd55-c46f-471c-8a2c-c9e9dc05279e",
       "rows": [
        [
         "0",
         "2024-01-02 00:00:00",
         "22922",
         "Amariah Lopez-Garcia",
         "Logistics",
         "HQ-5",
         "Q1'24"
        ],
        [
         "1",
         "2024-01-02 00:00:00",
         "99325",
         "Massiah Ventura",
         "Market Operations",
         "NV Las Vegas - Gowan IC",
         "Q1'24"
        ],
        [
         "2",
         "2024-01-02 00:00:00",
         "10548",
         "Adam Coffey",
         "Post Production",
         "TX Blue Mound IC",
         "Q1'24"
        ],
        [
         "3",
         "2024-01-02 00:00:00",
         "97922",
         "Quan Stinnie",
         "Reconditioning",
         "VA Chesterfield IC",
         "Q1'24"
        ],
        [
         "5",
         "2024-01-02 00:00:00",
         "95494",
         "Histo Louis",
         "Market Operations",
         "MA Boston - Norfolk",
         "Q1'24"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TERMINATIONDATE</th>\n",
       "      <th>EMPLOYEE_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>JOB_FAMILY_GROUP</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>QUARTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>22922</td>\n",
       "      <td>Amariah Lopez-Garcia</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>HQ-5</td>\n",
       "      <td>Q1'24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>99325</td>\n",
       "      <td>Massiah Ventura</td>\n",
       "      <td>Market Operations</td>\n",
       "      <td>NV Las Vegas - Gowan IC</td>\n",
       "      <td>Q1'24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>10548</td>\n",
       "      <td>Adam Coffey</td>\n",
       "      <td>Post Production</td>\n",
       "      <td>TX Blue Mound IC</td>\n",
       "      <td>Q1'24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>97922</td>\n",
       "      <td>Quan Stinnie</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>VA Chesterfield IC</td>\n",
       "      <td>Q1'24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>95494</td>\n",
       "      <td>Histo Louis</td>\n",
       "      <td>Market Operations</td>\n",
       "      <td>MA Boston - Norfolk</td>\n",
       "      <td>Q1'24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TERMINATIONDATE EMPLOYEE_ID                  NAME   JOB_FAMILY_GROUP  \\\n",
       "0      2024-01-02       22922  Amariah Lopez-Garcia          Logistics   \n",
       "1      2024-01-02       99325       Massiah Ventura  Market Operations   \n",
       "2      2024-01-02       10548           Adam Coffey    Post Production   \n",
       "3      2024-01-02       97922          Quan Stinnie     Reconditioning   \n",
       "5      2024-01-02       95494           Histo Louis  Market Operations   \n",
       "\n",
       "                  LOCATION QUARTER  \n",
       "0                     HQ-5   Q1'24  \n",
       "1  NV Las Vegas - Gowan IC   Q1'24  \n",
       "2         TX Blue Mound IC   Q1'24  \n",
       "3       VA Chesterfield IC   Q1'24  \n",
       "5      MA Boston - Norfolk   Q1'24  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(turnover_sql_terms.shape)\n",
    "turnover_sql_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "QUARTER",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "87c904a4-e5db-48e5-8c00-601b235fed6f",
       "rows": [
        [
         "Q1'24",
         "1674"
        ],
        [
         "Q1'25",
         "3155"
        ],
        [
         "Q2'24",
         "2061"
        ],
        [
         "Q2'25",
         "3257"
        ],
        [
         "Q3'24",
         "2740"
        ],
        [
         "Q3'25",
         "4387"
        ],
        [
         "Q4'24",
         "2553"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 7
       }
      },
      "text/plain": [
       "QUARTER\n",
       "Q1'24    1674\n",
       "Q1'25    3155\n",
       "Q2'24    2061\n",
       "Q2'25    3257\n",
       "Q3'24    2740\n",
       "Q3'25    4387\n",
       "Q4'24    2553\n",
       "dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turnover_sql_terms.groupby('QUARTER').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUN THIS WRITE CAREFULLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading data chunk num: 1: 100%|| 19827/19827 [00:01<00:00, 19663.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Insert Data\n",
    "\n",
    "db_snowflake_write.insert('TermEmployee',turnover_sql_terms,truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location/JobFamilyGroup Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Active Emp Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_df=db_snowflake.execute(\"\"\"\n",
    "\n",
    "--SELECT * FROM PEOPLEOPS_SANDBOX.SITERISK.ACTIVE_EMPLOYEES\n",
    "                                 \n",
    "\n",
    "SELECT\n",
    "    DATE_DAY as DATE,\n",
    "    CASE\n",
    "    WHEN JOB_FAMILY_GROUP like '%ADESA%' THEN 'ADESA'\n",
    "    ELSE JOB_FAMILY_GROUP\n",
    "    END as JOB_FAMILY_GROUP,\n",
    "    CASE\n",
    "        WHEN DATE_QUARTER = '2024-01-01' THEN 'Q1''24'\n",
    "        WHEN DATE_QUARTER = '2024-04-01' THEN 'Q2''24'\n",
    "        WHEN DATE_QUARTER = '2024-07-01' THEN 'Q3''24'\n",
    "        WHEN DATE_QUARTER = '2024-10-01' THEN 'Q4''24'\n",
    "        WHEN DATE_QUARTER = '2025-01-01' THEN 'Q1''25'\n",
    "        WHEN DATE_QUARTER = '2025-04-01' THEN 'Q2''25'\n",
    "        WHEN DATE_QUARTER = '2025-07-01' THEN 'Q3''25'\n",
    "                               \n",
    "    END AS Quarter,\n",
    "    LOCATION,\n",
    "    COUNT(*) as Active_employees\n",
    "FROM \n",
    "    PEOPLEOPS_SANDBOX.DEV.WORKDAY_EMPLOYEE_LINEAGE\n",
    "WHERE \n",
    "    DATA_TYPE in('ACTIVE','ON LEAVE')\n",
    "    AND EMPLOYEE_TYPE='Regular'\n",
    "    AND DATE_DAY>='2024-01-01'\n",
    "GROUP BY DATE_DAY,LOCATION,DATE_QUARTER,\n",
    "CASE\n",
    "    WHEN JOB_FAMILY_GROUP like '%ADESA%' THEN 'ADESA'\n",
    "    ELSE JOB_FAMILY_GROUP END\n",
    "ORDER BY DATE_DAY,JOB_FAMILY_GROUP,LOCATION,Active_employees;\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_df=active_df[active_df['JOB_FAMILY_GROUP'].isin(necessary_JobFamilyGroups) & active_df['QUARTER'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count the number of active employees on each day\n",
    "# active_df= active_emps.groupby(['DATE','JOB_FAMILY_GROUP','LOCATION','QUARTER'])\\\n",
    "#     .agg(employees=('EMPLOYEE_ID','count')).reset_index()\n",
    "\n",
    "# # Adding WeekNumber for based on Date column\n",
    "# active_df['WeekNumber']=active_df['Date'].dt.isocalendar().week # Add this for weekly turnover\n",
    "\n",
    "# # # Adding Quarter based on Date column\n",
    "# # active_df['Quarter'] = active_df['Date'].dt.to_period(\"Q\")\n",
    "# # active_df['Quarter'] = active_df['Quarter'].apply(lambda q: f\"{q.strftime('Q%q')}'{str(q.year)[2:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quarter calculation\n",
    "# Calculating the average headcount for the Quater\n",
    "# (Add Week Number in groupby for weekly turnover)\n",
    "\n",
    "active_qt_df=active_df.groupby(['QUARTER','JOB_FAMILY_GROUP','LOCATION'])\\\n",
    "    .agg(Avg_emp=('ACTIVE_EMPLOYEES','mean')).reset_index()\n",
    "\n",
    "# Rounding the weekly\n",
    "active_qt_df['Avg_emp']=round(active_qt_df['Avg_emp'],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_terms= db_snowflake.execute(\"\"\"\n",
    "\n",
    "SELECT * FROM PEOPLEOPS_SANDBOX.SITERISK.TERMEMPLOYEE\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of terms each day\n",
    "term_df= turnover_terms.groupby(['TERMINATIONDATE','JOB_FAMILY_GROUP','LOCATION','QUARTER'])\\\n",
    "    .agg(Terminations=('EMPLOYEE_ID','count')).reset_index()\n",
    "\n",
    "# # Renaming Termination Date\n",
    "# term_df=term_df.rename(columns={'TERMINATIONDATE':'Date'})\n",
    "\n",
    "# # Adding Weeknumber based on Termination Date\n",
    "# term_df['WeekNumber']=term_df['Date'].dt.isocalendar().week # Add this for weekly turnover\n",
    "\n",
    "# # Adding Quarter based on Date column\n",
    "# term_df['Quarter'] = term_df['Date'].dt.to_period(\"Q\")\n",
    "# term_df['Quarter'] = term_df['Quarter'].apply(lambda q: f\"{q.strftime('Q%q')}'{str(q.year)[2:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quarter calculation\n",
    "# Calculating the terms for the quarter\n",
    "\n",
    "term_qt_df=term_df.groupby(['QUARTER','JOB_FAMILY_GROUP','LOCATION'])\\\n",
    "    .agg(Terminations=('Terminations','sum')).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combining Active and Terms \n",
    "# turnover_df=pd.merge(active_df,term_df,on=['Date','Quarter','Location','JobFamilyGroup'],how='left')\n",
    "\n",
    "# # Fill NA\n",
    "# turnover_df=turnover_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quaterly Turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Active and Terms \n",
    "turnover_qt_df=pd.merge(active_qt_df,term_qt_df,on=['QUARTER','LOCATION','JOB_FAMILY_GROUP'],how='left')\n",
    "\n",
    "# Fill NA\n",
    "turnover_qt_df=turnover_qt_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_qt_df= turnover_qt_df.groupby(['QUARTER','JOB_FAMILY_GROUP','LOCATION']).\\\n",
    "                            agg(Avg_emp=('Avg_emp','mean'),\\\n",
    "                                Terminations=('Terminations','sum')).reset_index()\n",
    "\n",
    "# Calculating the turnover rate \n",
    "turnover_qt_df['Quaterly_Turnover']=round((turnover_qt_df['Terminations']/turnover_qt_df['Avg_emp'])*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_qt_df=turnover_qt_df.rename(columns={'QUARTER':'Quarter','JOB_FAMILY_GROUP':'JobFamilyGroup','LOCATION':'Location'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Function to parse quarter and year\n",
    "def parse_quarter(quarter_str):\n",
    "    match = re.match(r\"Q([1-4])'(\\d{2})\", quarter_str)\n",
    "    if match:\n",
    "        return int(match.group(2)) * 4 + int(match.group(1))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column for sorting\n",
    "turnover_qt_df['sort_key'] = turnover_qt_df['Quarter'].apply(parse_quarter)\n",
    "\n",
    "\n",
    "# Ensure the DataFrame is sorted by location, jobfamily, and sort_key\n",
    "turnover_qt_df = turnover_qt_df.sort_values(by=['Location', 'JobFamilyGroup', 'sort_key'])\n",
    "\n",
    "\n",
    "# Calculate the change in turnover for consecutive quarters\n",
    "turnover_qt_df['Turnover_change'] = turnover_qt_df.groupby(['Location', 'JobFamilyGroup'])['Quaterly_Turnover'].diff()\n",
    "\n",
    "\n",
    "# Drop the temporary sort_key column\n",
    "turnover_qt_df = turnover_qt_df.drop(columns=['sort_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_qt_df['Turnover_change']=turnover_qt_df['Turnover_change'].fillna(0).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge - Main DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=pd.merge(main_df,turnover_qt_df,on=['Quarter','JobFamilyGroup','Location'],how='left')\n",
    "\n",
    "# Removing avg_emp col\n",
    "# main_df.drop('Avg_emp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_df=main_df.drop(columns=['Terminations','Quaterly_Turnover','Turnover_change'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navex - Siterisk 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Navex\\\\navex_Q1'25.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Navex\\\\navex_Q2'25.csv\",\n",
       " \"X:\\\\People_Operations\\\\Secured\\\\Talent Analytics\\\\Anish Middela\\\\SiteRisk\\\\Navex\\\\navex_Q3'25.csv\"]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SITE RISK 2.0\n",
    "navex_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Location': 'AL Bessemer IC', 'JobFamilyGroup': 'Logistics'}, {'Location': 'AL Bessemer IC', 'JobFamilyGroup': 'Market Operations'}, {'Location': 'AL Bessemer IC', 'JobFamilyGroup': 'Post Production'}, {'Location': 'AL Bessemer IC', 'JobFamilyGroup': 'Reconditioning'}, {'Location': 'AL Birmingham', 'JobFamilyGroup': 'Market Operations'}]\n"
     ]
    }
   ],
   "source": [
    "valid_locations = main_df[main_df['Score'] > 0][['Location', 'JobFamilyGroup']].drop_duplicates().to_dict('records')\n",
    "\n",
    "print(valid_locations[:5]) # Print the first 5 to see the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "navex_df_main= pd.DataFrame()\n",
    "\n",
    "# Appending all the csv files into one DataFrame\n",
    "for file in navex_files:\n",
    "    df_temp_navex = pd.read_csv(file)\n",
    "\n",
    "\n",
    "    # Strip leading and trailing spaces from column names\n",
    "    df_temp_navex.columns = df_temp_navex.columns.str.strip()\n",
    "\n",
    "\n",
    "    # Add Quarter information\n",
    "    df_temp_navex['Quarter'] = file.split('_')[-1].split('.')[0]\n",
    "\n",
    "\n",
    "    # Concatenate to main DataFrame\n",
    "    navex_df_main = pd.concat([navex_df_main, df_temp_navex], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "navex_df_main= navex_df_main.drop(columns=['LATITUTDE','LONGITUDE'])\n",
    "navex_df_main=navex_df_main.drop_duplicates()\n",
    "navex_df_main=navex_df_main.rename(columns={'BRANCH_NUMBER':'JobFamilyGroup'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "def map_location(row, valid_locations, min_score=80):\n",
    "    \"\"\"\n",
    "    Maps a given location name to the best matching valid location\n",
    "    within the same job family group, prioritizing specific conditions.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from the DataFrame containing 'LOCATION_NAME' and 'JOBFAMILYGROUP'.\n",
    "        valid_locations (list): A list of dictionaries with 'Location' and 'JobFamilyGroup'.\n",
    "        min_score (int): Minimum fuzzy match score (0-100) to consider a match.\n",
    "\n",
    "    Returns:\n",
    "        str: The best matching valid location, or None if no good match is found.\n",
    "    \"\"\"\n",
    "    location_name = row['LOCATION_NAME']\n",
    "    job_family = row['JobFamilyGroup']\n",
    "\n",
    "    if pd.isna(location_name):\n",
    "        return None\n",
    "\n",
    "    location_name_upper = location_name.upper()\n",
    "\n",
    "    if location_name == 'Remote':\n",
    "        return 'Remote'\n",
    "    elif location_name == 'Other':\n",
    "        return 'Other'\n",
    "    elif 'VM' in location_name_upper or 'ADESA' in location_name_upper or 'VLC' in location_name_upper:\n",
    "        return location_name\n",
    "    else:\n",
    "        # Filter valid locations by job family group\n",
    "        relevant_locations = [\n",
    "            loc['Location'] for loc in valid_locations if loc['JobFamilyGroup'] == job_family\n",
    "        ]\n",
    "        if not relevant_locations:\n",
    "            return None  # No valid locations for this job family\n",
    "\n",
    "        best_match, score = process.extractOne(location_name, relevant_locations, scorer=fuzz.token_set_ratio)\n",
    "        if score >= min_score:\n",
    "            return best_match\n",
    "        return None\n",
    "\n",
    "# Assuming your DataFrame 'df' has columns 'LOCATION_NAME' and 'JOBFAMILYGROUP'\n",
    "navex_df_main['Mapped_Location'] = navex_df_main.apply(map_location, axis=1, valid_locations=valid_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LOCATION_NAME",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "JobFamilyGroup",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Mapped_Location",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "1213a1e7-5b81-4aee-9f57-b615c727cd68",
       "rows": [
        [
         "0",
         "FL Haines City IC",
         "Logistics",
         "FL Haines City IC"
        ],
        [
         "2",
         "NJ Delanco IC",
         "Logistics",
         "NJ Delanco IC"
        ],
        [
         "4",
         "OK Oklahoma City IC",
         "Reconditioning",
         "OK Oklahoma City IC"
        ],
        [
         "7",
         "AZ Tolleson IC",
         "Reconditioning",
         "AZ Tolleson IC"
        ],
        [
         "8",
         "TX Blue Mound IC",
         "Reconditioning",
         "TX Blue Mound IC"
        ],
        [
         "9",
         "CA Riverside",
         "ADESA",
         "CA Riverside"
        ],
        [
         "12",
         "OH Cincinnati - William",
         "ADESA",
         "OH Cincinnati - William"
        ],
        [
         "16",
         "Tolleson IC",
         "Unknown",
         null
        ],
        [
         "17",
         "GA Atlanta - Fairburn",
         "Reconditioning",
         "GA Atlanta - Fairburn"
        ],
        [
         "18",
         "AZ Tolleson IC",
         "Reconditioning",
         "AZ Tolleson IC"
        ],
        [
         "19",
         "VA Washington DC - Dulles Hub",
         "Market Operations",
         "VA Washington DC - Dulles"
        ],
        [
         "20",
         "AL Bessemer IC",
         "Reconditioning",
         "AL Bessemer IC"
        ],
        [
         "21",
         "Remote",
         null,
         "Remote"
        ],
        [
         "22",
         "Other",
         null,
         "Other"
        ],
        [
         "23",
         "CA San Francisco - Daly City VM",
         null,
         "CA San Francisco - Daly City VM"
        ],
        [
         "27",
         "Philadelphia VM",
         "Market Operations",
         "Philadelphia VM"
        ],
        [
         "29",
         "Other",
         null,
         "Other"
        ],
        [
         "31",
         "OK Oklahoma City IC",
         "Logistics",
         "OK Oklahoma City IC"
        ],
        [
         "33",
         "Houston VLC",
         "Reconditioning",
         "Houston VLC"
        ],
        [
         "34",
         "CA San Francisco - Richmond",
         null,
         null
        ],
        [
         "35",
         "VA Chesterfield IC",
         "Reconditioning",
         "VA Chesterfield IC"
        ],
        [
         "36",
         "Other",
         null,
         "Other"
        ],
        [
         "41",
         "OK Oklahoma City - VM",
         "Market Operations",
         "OK Oklahoma City - VM"
        ],
        [
         "42",
         "Other",
         null,
         "Other"
        ],
        [
         "43",
         "NJ Delanco IC",
         null,
         null
        ],
        [
         "44",
         "Other",
         null,
         "Other"
        ],
        [
         "45",
         "HQ Riverpoint",
         null,
         null
        ],
        [
         "47",
         "IL University Park IC",
         "Reconditioning",
         "IL University Park IC"
        ],
        [
         "48",
         "Other",
         null,
         "Other"
        ],
        [
         "50",
         "HQ Riverpoint",
         null,
         null
        ],
        [
         "51",
         "Elyria, OH",
         "Reconditioning",
         "OH Elyria IC"
        ],
        [
         "53",
         "TX Blue Mound IC",
         "Reconditioning",
         "TX Blue Mound IC"
        ],
        [
         "54",
         "OK Oklahoma City IC",
         "Logistics",
         "OK Oklahoma City IC"
        ],
        [
         "55",
         "AZ Tolleson IC",
         "Reconditioning",
         "AZ Tolleson IC"
        ],
        [
         "56",
         "AR Little Rock - McNeill",
         "Market Operations",
         "AR Little Rock - McNeill"
        ],
        [
         "58",
         "NC Concord IC",
         "Reconditioning",
         "NC Concord IC"
        ],
        [
         "59",
         "HQ-5",
         "Titles",
         null
        ],
        [
         "65",
         "HQ-5",
         "Regulatory Operations",
         "HQ-5"
        ],
        [
         "66",
         "TX El Paso - Northwestern Log Hub",
         null,
         null
        ],
        [
         "67",
         "Trenton IC",
         "Reconditioning",
         "OH Trenton IC"
        ],
        [
         "71",
         "TX Houston",
         "Logistics",
         "TX Houston - Sam Houston"
        ],
        [
         "72",
         "IL University Park IC",
         "Reconditioning",
         "IL University Park IC"
        ],
        [
         "73",
         "GA Atlanta - Union City",
         "Market Operations",
         "GA Atlanta - Union City"
        ],
        [
         "74",
         "OH Heath IC",
         "Reconditioning",
         "OH Heath IC"
        ],
        [
         "76",
         "Other",
         null,
         "Other"
        ],
        [
         "79",
         "IL University Park IC",
         "Reconditioning",
         "IL University Park IC"
        ],
        [
         "80",
         "TX Blue Mound IC",
         "Reconditioning",
         "TX Blue Mound IC"
        ],
        [
         "81",
         "OK Oklahoma City IC",
         "Reconditioning",
         "OK Oklahoma City IC"
        ],
        [
         "82",
         "IL University Park IC",
         "Reconditioning",
         "IL University Park IC"
        ],
        [
         "83",
         "IL University Park IC",
         "Reconditioning",
         "IL University Park IC"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1335
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION_NAME</th>\n",
       "      <th>JobFamilyGroup</th>\n",
       "      <th>Mapped_Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FL Haines City IC</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>FL Haines City IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ Delanco IC</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>NJ Delanco IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK Oklahoma City IC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>OK Oklahoma City IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AZ Tolleson IC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>AZ Tolleson IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TX Blue Mound IC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>TX Blue Mound IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>IN Indianapolis IC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>IN Indianapolis IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>Schaumburg - VM</td>\n",
       "      <td>Market Operations</td>\n",
       "      <td>Schaumburg - VM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>GA Winder IC</td>\n",
       "      <td>Safe and Secure</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>IN Indianapolis IC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>IN Indianapolis IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1335 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LOCATION_NAME     JobFamilyGroup      Mapped_Location\n",
       "0       FL Haines City IC          Logistics    FL Haines City IC\n",
       "2           NJ Delanco IC          Logistics        NJ Delanco IC\n",
       "4     OK Oklahoma City IC     Reconditioning  OK Oklahoma City IC\n",
       "7          AZ Tolleson IC     Reconditioning       AZ Tolleson IC\n",
       "8        TX Blue Mound IC     Reconditioning     TX Blue Mound IC\n",
       "...                   ...                ...                  ...\n",
       "2267   IN Indianapolis IC     Reconditioning   IN Indianapolis IC\n",
       "2268      Schaumburg - VM  Market Operations      Schaumburg - VM\n",
       "2269         GA Winder IC    Safe and Secure                 None\n",
       "2271   IN Indianapolis IC     Reconditioning   IN Indianapolis IC\n",
       "2273                Other                NaN                Other\n",
       "\n",
       "[1335 rows x 3 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navex_df_main[['LOCATION_NAME', 'JobFamilyGroup', 'Mapped_Location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "navex_df_main['Mapped_Location']= np.where(navex_df_main['Mapped_Location'].isna(),navex_df_main['LOCATION_NAME'],navex_df_main['Mapped_Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ASSIGNED_TIER",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "JobFamilyGroup",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "LOCATION_NAME",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CASE_NUMBER",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PRIMARY_ISSUE",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CASE_TYPE",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "CASE_STATUS",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DATE_OPENED",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DAYS_OPEN",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DATE_CLOSED",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CASE_OUTCOME",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ACTION_TAKEN",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Quarter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MONTH_OPENED",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Mapped_Location",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "92a15293-d8e9-4e31-a1ab-7b900032cea8",
       "rows": [
        [
         "0",
         "Carvana Logistics, LLC",
         "Logistics",
         "FL Haines City IC",
         "4647",
         "Abuse of Authority/Inappropriate Supervisory Directions",
         null,
         "In Process",
         "02/20/2025",
         "41",
         "04/02/2025",
         "Substantiated",
         "Training/Coaching",
         "Q1'25",
         null,
         "FL Haines City IC"
        ],
        [
         "2",
         "Carvana, LLC",
         "Logistics",
         "NJ Delanco IC",
         "4813",
         "Violation of Carvana Leadership Values (Internal Use Only)",
         "Allegation",
         "In Process",
         "03/22/2025",
         "11",
         "04/02/2025",
         "Referred",
         "No Action Taken",
         "Q1'25",
         null,
         "NJ Delanco IC"
        ],
        [
         "4",
         "Carvana, LLC",
         "Reconditioning",
         "OK Oklahoma City IC",
         "4835",
         "Discrimination/ Harassment based on membership in a protected group (e.g., race, religion, age, sex, disability, political affiliation, etc.)",
         "Allegation",
         "Closed",
         "03/27/2025",
         "5",
         "04/01/2025",
         "Unsubstantiated",
         "Training/Coaching",
         "Q1'25",
         null,
         "OK Oklahoma City IC"
        ],
        [
         "7",
         "Carvana, LLC",
         "Reconditioning",
         "AZ Tolleson IC",
         "4852",
         "Abuse of Authority/Inappropriate Supervisory Directions",
         "Allegation",
         "Closed",
         "03/31/2025",
         "1",
         "04/01/2025",
         "Referred",
         "No Action Taken",
         "Q1'25",
         null,
         "AZ Tolleson IC"
        ],
        [
         "8",
         "Carvana, LLC",
         "Reconditioning",
         "TX Blue Mound IC",
         "4855",
         "Abuse of Authority/Inappropriate Supervisory Directions",
         "Allegation",
         "Closed",
         "03/31/2025",
         "1",
         "04/01/2025",
         "Disproved",
         "Policy/ Process Review",
         "Q1'25",
         null,
         "TX Blue Mound IC"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASSIGNED_TIER</th>\n",
       "      <th>JobFamilyGroup</th>\n",
       "      <th>LOCATION_NAME</th>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <th>PRIMARY_ISSUE</th>\n",
       "      <th>CASE_TYPE</th>\n",
       "      <th>CASE_STATUS</th>\n",
       "      <th>DATE_OPENED</th>\n",
       "      <th>DAYS_OPEN</th>\n",
       "      <th>DATE_CLOSED</th>\n",
       "      <th>CASE_OUTCOME</th>\n",
       "      <th>ACTION_TAKEN</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>MONTH_OPENED</th>\n",
       "      <th>Mapped_Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carvana Logistics, LLC</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>FL Haines City IC</td>\n",
       "      <td>4647</td>\n",
       "      <td>Abuse of Authority/Inappropriate Supervisory D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In Process</td>\n",
       "      <td>02/20/2025</td>\n",
       "      <td>41</td>\n",
       "      <td>04/02/2025</td>\n",
       "      <td>Substantiated</td>\n",
       "      <td>Training/Coaching</td>\n",
       "      <td>Q1'25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FL Haines City IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carvana, LLC</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>NJ Delanco IC</td>\n",
       "      <td>4813</td>\n",
       "      <td>Violation of Carvana Leadership Values (Intern...</td>\n",
       "      <td>Allegation</td>\n",
       "      <td>In Process</td>\n",
       "      <td>03/22/2025</td>\n",
       "      <td>11</td>\n",
       "      <td>04/02/2025</td>\n",
       "      <td>Referred</td>\n",
       "      <td>No Action Taken</td>\n",
       "      <td>Q1'25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ Delanco IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carvana, LLC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>OK Oklahoma City IC</td>\n",
       "      <td>4835</td>\n",
       "      <td>Discrimination/ Harassment based on membership...</td>\n",
       "      <td>Allegation</td>\n",
       "      <td>Closed</td>\n",
       "      <td>03/27/2025</td>\n",
       "      <td>5</td>\n",
       "      <td>04/01/2025</td>\n",
       "      <td>Unsubstantiated</td>\n",
       "      <td>Training/Coaching</td>\n",
       "      <td>Q1'25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK Oklahoma City IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Carvana, LLC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>AZ Tolleson IC</td>\n",
       "      <td>4852</td>\n",
       "      <td>Abuse of Authority/Inappropriate Supervisory D...</td>\n",
       "      <td>Allegation</td>\n",
       "      <td>Closed</td>\n",
       "      <td>03/31/2025</td>\n",
       "      <td>1</td>\n",
       "      <td>04/01/2025</td>\n",
       "      <td>Referred</td>\n",
       "      <td>No Action Taken</td>\n",
       "      <td>Q1'25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ Tolleson IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Carvana, LLC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>TX Blue Mound IC</td>\n",
       "      <td>4855</td>\n",
       "      <td>Abuse of Authority/Inappropriate Supervisory D...</td>\n",
       "      <td>Allegation</td>\n",
       "      <td>Closed</td>\n",
       "      <td>03/31/2025</td>\n",
       "      <td>1</td>\n",
       "      <td>04/01/2025</td>\n",
       "      <td>Disproved</td>\n",
       "      <td>Policy/ Process Review</td>\n",
       "      <td>Q1'25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX Blue Mound IC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ASSIGNED_TIER  JobFamilyGroup        LOCATION_NAME  CASE_NUMBER  \\\n",
       "0  Carvana Logistics, LLC       Logistics    FL Haines City IC         4647   \n",
       "2            Carvana, LLC       Logistics        NJ Delanco IC         4813   \n",
       "4            Carvana, LLC  Reconditioning  OK Oklahoma City IC         4835   \n",
       "7            Carvana, LLC  Reconditioning       AZ Tolleson IC         4852   \n",
       "8            Carvana, LLC  Reconditioning     TX Blue Mound IC         4855   \n",
       "\n",
       "                                       PRIMARY_ISSUE   CASE_TYPE CASE_STATUS  \\\n",
       "0  Abuse of Authority/Inappropriate Supervisory D...         NaN  In Process   \n",
       "2  Violation of Carvana Leadership Values (Intern...  Allegation  In Process   \n",
       "4  Discrimination/ Harassment based on membership...  Allegation      Closed   \n",
       "7  Abuse of Authority/Inappropriate Supervisory D...  Allegation      Closed   \n",
       "8  Abuse of Authority/Inappropriate Supervisory D...  Allegation      Closed   \n",
       "\n",
       "  DATE_OPENED  DAYS_OPEN DATE_CLOSED     CASE_OUTCOME            ACTION_TAKEN  \\\n",
       "0  02/20/2025         41  04/02/2025    Substantiated       Training/Coaching   \n",
       "2  03/22/2025         11  04/02/2025         Referred         No Action Taken   \n",
       "4  03/27/2025          5  04/01/2025  Unsubstantiated       Training/Coaching   \n",
       "7  03/31/2025          1  04/01/2025         Referred         No Action Taken   \n",
       "8  03/31/2025          1  04/01/2025        Disproved  Policy/ Process Review   \n",
       "\n",
       "  Quarter MONTH_OPENED      Mapped_Location  \n",
       "0   Q1'25          NaN    FL Haines City IC  \n",
       "2   Q1'25          NaN        NJ Delanco IC  \n",
       "4   Q1'25          NaN  OK Oklahoma City IC  \n",
       "7   Q1'25          NaN       AZ Tolleson IC  \n",
       "8   Q1'25          NaN     TX Blue Mound IC  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navex_df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Quarter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2d521bec-4309-434c-893c-e2259752c14a",
       "rows": [
        [
         "Q3'25",
         "492"
        ],
        [
         "Q1'25",
         "449"
        ],
        [
         "Q2'25",
         "394"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "Quarter\n",
       "Q3'25    492\n",
       "Q1'25    449\n",
       "Q2'25    394\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navex_df_main.value_counts('Quarter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ASSIGNED_TIER', 'JobFamilyGroup', 'LOCATION_NAME', 'CASE_NUMBER',\n",
       "       'PRIMARY_ISSUE', 'CASE_TYPE', 'CASE_STATUS', 'DATE_OPENED', 'DAYS_OPEN',\n",
       "       'DATE_CLOSED', 'CASE_OUTCOME', 'ACTION_TAKEN', 'Quarter',\n",
       "       'MONTH_OPENED', 'Mapped_Location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navex_df_main.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "navex_df_main=navex_df_main.rename(columns={'LOCATION_NAME':'Old_Location','Mapped_Location':'Location'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navex_df_main= navex_df_main.drop(columns=['QUARTER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading data chunk num: 1: 100%|| 1335/1335 [00:00<00:00, 1947.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Snowflake Dump\n",
    "navex_df_snowflake= navex_df_main.copy()\n",
    "db_snowflake_write.drop_table('Navex')\n",
    "db_snowflake_write.dump('Navex',navex_df_snowflake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navex Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "navex_df= navex_df_main.copy()\n",
    "navex_df= navex_df[navex_df['JobFamilyGroup'].isin(necessary_JobFamilyGroups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "navex_df= navex_df.groupby(['Location','JobFamilyGroup','Quarter'])\\\n",
    "    .agg(Navex_Incidents=('CASE_NUMBER','nunique')).reset_index()\n",
    "    # .agg(Navex_Incidents=('CASE_STATUS','count')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Quarter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "dad38d0c-dd9b-45c8-a03c-3961067e8270",
       "rows": [
        [
         "Q3'25",
         "101"
        ],
        [
         "Q2'25",
         "100"
        ],
        [
         "Q1'25",
         "96"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "Quarter\n",
       "Q3'25    101\n",
       "Q2'25    100\n",
       "Q1'25     96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navex_df.value_counts('Quarter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navex_df['Navex_Incidents'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "JobFamilyGroup",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Quarter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Navex_Incidents",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "83d6e08c-5127-4488-91db-9f869baa55c5",
       "rows": [
        [
         "0",
         "ADESA - Atlanta - VLC",
         "Reconditioning",
         "Q3'25",
         "1"
        ],
        [
         "1",
         "ADESA - Boston - VLC",
         "Reconditioning",
         "Q3'25",
         "1"
        ],
        [
         "2",
         "ADESA - Dallas - VLC",
         "Market Operations",
         "Q3'25",
         "1"
        ],
        [
         "3",
         "ADESA - Dallas - VLC",
         "Reconditioning",
         "Q3'25",
         "1"
        ],
        [
         "4",
         "ADESA - Indianapolis - VLC",
         "Reconditioning",
         "Q3'25",
         "1"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>JobFamilyGroup</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Navex_Incidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADESA - Atlanta - VLC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>Q3'25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADESA - Boston - VLC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>Q3'25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADESA - Dallas - VLC</td>\n",
       "      <td>Market Operations</td>\n",
       "      <td>Q3'25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADESA - Dallas - VLC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>Q3'25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADESA - Indianapolis - VLC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>Q3'25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Location     JobFamilyGroup Quarter  Navex_Incidents\n",
       "0       ADESA - Atlanta - VLC     Reconditioning   Q3'25                1\n",
       "1        ADESA - Boston - VLC     Reconditioning   Q3'25                1\n",
       "2        ADESA - Dallas - VLC  Market Operations   Q3'25                1\n",
       "3        ADESA - Dallas - VLC     Reconditioning   Q3'25                1\n",
       "4  ADESA - Indianapolis - VLC     Reconditioning   Q3'25                1"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navex_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=pd.merge(main_df,navex_df,on=['Location','JobFamilyGroup','Quarter'],how='left')\n",
    "# main_df['Navex_Incidents']=main_df['Navex_Incidents'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Employees- Location/JobProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD Total Emp LOGIC\n",
    "#Pulling All Locations,Costcentres Required and Total EMployees\n",
    "\n",
    "# totalemp_df= db_snowflake.execute(\"\"\"\n",
    "\n",
    "# SELECT LOCATION_NAME,JOB_FAMILY_GROUP, count(*) as TotalEmployees\n",
    "# from shared.dw.dim_employee\n",
    "# where JOB_FAMILY_GROUP in ('RECONDITIONING','MARKET_OPERATIONS','REGULATORY_OPERATIONS','LOGISTICS','WHOLESALE_OPERATIONS')\n",
    "# AND (is_employee_active='True' or  is_on_loa='True')\n",
    "# group by LOCATION_NAME,JOB_FAMILY_GROUP\n",
    "# order by JOB_FAMILY_GROUP,location_name,TotalEmployees desc;\n",
    "\n",
    "# \"\"\")\n",
    "\n",
    "# # Pulling all Locations, Total Emp for ADESA - due to many misconsistencies with data\n",
    "\n",
    "# ADESAemp_df= db_snowflake.execute(\"\"\"\n",
    "\n",
    "# SELECT LOCATION_NAME,'ADESA' as CostCentre,count(*) as TotalEmployees\n",
    "# from shared.dw.dim_employee\n",
    "# where JOB_PROFILE like ('%ADESA%')\n",
    "# and is_employee_active='True' or  is_on_loa='True'\n",
    "# group by LOCATION_NAME;\n",
    "\n",
    "# \"\"\")\n",
    "\n",
    "\n",
    "# Cleaning of Names\n",
    "\n",
    "# totalemp_df=totalemp_df.rename(columns={'LOCATION_NAME':'Location','JOB_FAMILY_GROUP':'CostCentre','TOTALEMPLOYEES':'TotalEmployees'})\n",
    "\n",
    "# ADESAemp_df=ADESAemp_df.rename(columns={'LOCATION_NAME':'Location','COSTCENTRE':'CostCentre','TOTALEMPLOYEES':'TotalEmployees'})\n",
    "\n",
    "# # Rename Coscentre names\n",
    "# totalemp_df['CostCentre']=totalemp_df['CostCentre'].replace({'RECONDITIONING':'Reconditioning',\n",
    "#                                        'MARKET_OPERATIONS':'Market Operations',\n",
    "#                                        'REGULATORY_OPERATIONS':'Regulatory Operations',\n",
    "#                                        'LOGISTICS':'Logistics',\n",
    "#                                        'WHOLESALE_OPERATIONS':'Wholesale Operations'})\n",
    "\n",
    "# # Concat ADESA and TotalEmp\n",
    "# totalemp_df = pd.concat([totalemp_df,ADESAemp_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# totalemp_Loc_Jbp_df = pd.read_sql_query(\"\"\"\n",
    "\n",
    "# SELECT \n",
    "#     JobFamilyGroup,\n",
    "#     Location,\n",
    "#     count(*)as total_employees\n",
    "# FROM \n",
    "#     PeopleOps.workday.tblEmployee\n",
    "# WHERE \n",
    "#     ActiveStatus = 1\n",
    "#     AND SSIS_IsDeleted = 0\n",
    "#     AND EmployeeType = 'Regular'\n",
    "# \tAnd JobProfile Not like '%ADESA%'\n",
    "# GROUP By\n",
    "# \tJobFamilyGroup,\n",
    "#     Location\n",
    "# Order By \n",
    "# \ttotal_employees desc,\n",
    "# \tJobFamilyGroup,\n",
    "#     Location\n",
    "\n",
    "# \"\"\",odbcconn)\n",
    "\n",
    "# total_emp_ADESA= pd.read_sql_query(\"\"\"\n",
    "\n",
    "# SELECT \n",
    "#     'ADESA' as JobFamilyGroup,\n",
    "#     Location,\n",
    "#     count(*)as total_employees\n",
    "# FROM \n",
    "#     PeopleOps.workday.tblEmployee\n",
    "# WHERE \n",
    "#     ActiveStatus = 1\n",
    "#     AND SSIS_IsDeleted = 0\n",
    "#     AND EmployeeType = 'Regular'\n",
    "# \tAND JobProfile like '%ADESA%'\n",
    "# GROUP By\n",
    "#     Location\n",
    "# Order By \n",
    "# \ttotal_employees desc,\n",
    "#     Location\n",
    "\n",
    "# \"\"\",odbcconn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** ADD QUARTER DATA IN 'CASE' STATEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT JOB_FAMILY_GROUP,LOCATION,\n",
    "#     CASE\n",
    "#         WHEN DATE_QUARTER = '2024-01-01' THEN 'Q1''24'\n",
    "#         WHEN DATE_QUARTER = '2024-04-01' THEN 'Q2''24'\n",
    "#         WHEN DATE_QUARTER = '2024-07-01' THEN 'Q3''24'\n",
    "#         ELSE 'Unknown'\n",
    "#     END AS Quarter\n",
    "#     ,Count(*) as Total_Employees\n",
    "# FROM PEOPLEOPS_SANDBOX.DEV.WORKDAY_EMPLOYEE_LINEAGE\n",
    "# WHERE DATA_TYPE='ACTIVE'\n",
    "# AND DATEDIFF(DAY,DATE_QUARTER,DATE_DAY)=90\n",
    "# AND DATE_DAY>='2024-01-01'\n",
    "# AND JOB_PROFILE NOT Like '%ADESA%'\n",
    "# GROUP BY JOB_FAMILY_GROUP,LOCATION,DATE_QUARTER\n",
    "# ORDER BY Total_Employees desc,\n",
    "# JOB_FAMILY_GROUP,\n",
    "# LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalemp_Loc_Jbp_df = db_snowflake.execute(\"\"\"\n",
    "                                          \n",
    "SELECT\n",
    "    CASE\n",
    "    WHEN JOB_FAMILY_GROUP like '%ADESA%' THEN 'ADESA'\n",
    "    ELSE JOB_FAMILY_GROUP\n",
    "    END as JOB_FAMILY_GROUP,\n",
    "    CASE\n",
    "        WHEN DATE_QUARTER = '2024-01-01' THEN 'Q1''24'\n",
    "        WHEN DATE_QUARTER = '2024-04-01' THEN 'Q2''24'\n",
    "        WHEN DATE_QUARTER = '2024-07-01' THEN 'Q3''24'\n",
    "        WHEN DATE_QUARTER = '2024-10-01' THEN 'Q4''24'\n",
    "        WHEN DATE_QUARTER = '2025-01-01' THEN 'Q1''25'                                                                           \n",
    "        WHEN DATE_QUARTER = '2025-04-01' THEN 'Q2''25'\n",
    "        WHEN DATE_QUARTER = '2025-07-01' THEN 'Q3''25'                                                                          \n",
    "    END AS Quarter,\n",
    "    LOCATION,\n",
    "    COUNT(*) as Total_employees\n",
    "FROM \n",
    "    PEOPLEOPS_SANDBOX.DEV.WORKDAY_EMPLOYEE_LINEAGE\n",
    "WHERE \n",
    "    DATA_TYPE = 'ACTIVE'\n",
    "    AND EMPLOYEE_TYPE='Regular'\n",
    "    --AND DATE_QUARTER IN ('2024-01-01','2024-04-01','2024-07-01','2024-10-01','2025-01-01')\n",
    "    AND DATEDIFF(DAY,DATE_QUARTER,DATE_DAY)=89\n",
    "    AND DATE_DAY>='2024-01-01'\n",
    "GROUP BY DATE_DAY,LOCATION,DATE_QUARTER,\n",
    "CASE\n",
    "    WHEN JOB_FAMILY_GROUP like '%ADESA%' THEN 'ADESA'\n",
    "    ELSE JOB_FAMILY_GROUP END\n",
    "ORDER BY DATE_DAY,JOB_FAMILY_GROUP,LOCATION,Total_employees;\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalemp_Loc_Jbp_df=totalemp_Loc_Jbp_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalemp_Loc_Jbp_df=totalemp_Loc_Jbp_df[totalemp_Loc_Jbp_df['JOB_FAMILY_GROUP'].isin(necessary_JobFamilyGroups) & totalemp_Loc_Jbp_df['QUARTER'].notna()]\n",
    "\n",
    "totalemp_Loc_Jbp_df=totalemp_Loc_Jbp_df.rename(columns={'LOCATION':'Location','JOB_FAMILY_GROUP':'JobFamilyGroup','QUARTER':'Quarter','TOTAL_EMPLOYEES':'Total_Employees'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Quarter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "484a44b5-aa9f-4ea8-8758-2def06fe3424",
       "rows": [
        [
         "Q1'24",
         "399"
        ],
        [
         "Q1'25",
         "419"
        ],
        [
         "Q2'24",
         "412"
        ],
        [
         "Q2'25",
         "428"
        ],
        [
         "Q3'24",
         "420"
        ],
        [
         "Q3'25",
         "439"
        ],
        [
         "Q4'24",
         "401"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 7
       }
      },
      "text/plain": [
       "Quarter\n",
       "Q1'24    399\n",
       "Q1'25    419\n",
       "Q2'24    412\n",
       "Q2'25    428\n",
       "Q3'24    420\n",
       "Q3'25    439\n",
       "Q4'24    401\n",
       "dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalemp_Loc_Jbp_df.groupby('Quarter').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_emp_ADESA= db_snowflake.execute(\"\"\"\n",
    "\n",
    "# SELECT 'ADESA' as JOB_FAMILY_GROUP,LOCATION,\n",
    "#     CASE\n",
    "#         WHEN DATE_QUARTER = '2024-01-01' THEN 'Q1''24'\n",
    "#         WHEN DATE_QUARTER = '2024-04-01' THEN 'Q2''24'\n",
    "#         WHEN DATE_QUARTER = '2024-07-01' THEN 'Q3''24'\n",
    "#         ELSE 'Unknown'\n",
    "#     END AS Quarter\n",
    "#     ,Count(*) as Total_Employees\n",
    "# FROM PEOPLEOPS_SANDBOX.DEV.WORKDAY_EMPLOYEE_LINEAGE\n",
    "# WHERE DATA_TYPE='ACTIVE'\n",
    "# AND \n",
    "# AND DATEDIFF(DAY,DATE_QUARTER,DATE_DAY)=90\n",
    "# AND DATE_DAY>='2024-01-01'\n",
    "# AND JOB_PROFILE Like '%ADESA%'\n",
    "# GROUP BY LOCATION,DATE_QUARTER\n",
    "# ORDER BY Total_Employees desc,\n",
    "# LOCATION;\n",
    "\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# totalemp_Loc_Jbp_df=pd.concat([totalemp_Loc_Jbp_df,total_emp_ADESA])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Qt Avg Emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_qt_df=active_qt_df.rename(columns={'LOCATION':'Location','JOB_FAMILY_GROUP':'JobFamilyGroup','QUARTER':'Quarter','Avg_emp':'Average_Headcount'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge- Main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df= pd.merge(main_df,totalemp_Loc_Jbp_df,on=['Location','JobFamilyGroup','Quarter'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['Location']=main_df['Location'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_df=main_df.drop(columns=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_df=pd.merge(main_df,active_qt_df,on=['Location','JobFamilyGroup','Quarter'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37401.0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['PIPs & CARs'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leadership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadership = db_snowflake.execute(\"\"\" \n",
    "with cte as (\n",
    "SELECT DATE_WEEK,LOCATION,JOB_FAMILY_GROUP,SUM(TOTAL_LEADERS) as TOTAL_LEADERS, SUM(LEADER_HIRED) as LEADER_HIRED, SUM(TERMINATIONS) as LEADER_TERMINATIONS\n",
    "FROM PEOPLEOPS_SANDBOX.SITERISK.LEADERSHIP\n",
    "-- WHERE LOCATION='MA Boston - Western'\n",
    "-- AND JOB_FAMILY_GROUP ='Reconditioning'\n",
    "GROUP BY ALL\n",
    ")\n",
    "\n",
    "-- SELECT * FROM cte\n",
    "-- WHERE LOCATION='MA Boston - Western'\n",
    "-- AND JOB_FAMILY_GROUP='ADESA'\n",
    "-- ORDER BY DATE_WEEK;\n",
    "\n",
    "SELECT\n",
    "DATE_TRUNC('quarter',DATE_WEEK) as DATE_QUARTER\n",
    ",    CASE\n",
    "        WHEN DATE_QUARTER = '2025-01-01' THEN 'Q1''25'                                                                           \n",
    "        WHEN DATE_QUARTER = '2025-04-01' THEN 'Q2''25'\n",
    "        WHEN DATE_QUARTER = '2025-07-01' THEN 'Q3''25'\n",
    "        WHEN DATE_QUARTER = '2025-10-01' THEN 'Q4''25'                                                                          \n",
    "    END AS Quarter\n",
    ",LOCATION\n",
    ",JOB_FAMILY_GROUP\n",
    ",ROUND(AVG(TOTAL_LEADERS),0) as AVG_LEADERS\n",
    ",SUM(LEADER_HIRED) as LEADER_HIRED\n",
    ",SUM(LEADER_TERMINATIONS) as LEADER_TERMED\n",
    "FROM cte\n",
    "GROUP BY ALL;\n",
    "                                   \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DATE_QUARTER",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "QUARTER",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "LOCATION",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "JOB_FAMILY_GROUP",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AVG_LEADERS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LEADER_HIRED",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LEADER_TERMED",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "99c09f91-63d0-4f7b-ad66-667be09b0535",
       "rows": [
        [
         "0",
         "2025-01-01",
         "Q1'25",
         "NV Las Vegas - Gowan IC",
         "Logistics",
         "1.0",
         null,
         null
        ],
        [
         "1",
         "2025-07-01",
         "Q3'25",
         "NC Concord IC",
         "Logistics",
         "2.0",
         null,
         "2.0"
        ],
        [
         "2",
         "2025-04-01",
         "Q2'25",
         "NC Concord IC",
         "Logistics",
         "2.0",
         null,
         null
        ],
        [
         "3",
         "2025-04-01",
         "Q2'25",
         "VA Chesterfield IC",
         "Reconditioning",
         "4.0",
         null,
         null
        ],
        [
         "4",
         "2025-04-01",
         "Q2'25",
         "ND Fargo",
         "ADESA",
         "1.0",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_QUARTER</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>JOB_FAMILY_GROUP</th>\n",
       "      <th>AVG_LEADERS</th>\n",
       "      <th>LEADER_HIRED</th>\n",
       "      <th>LEADER_TERMED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Q1'25</td>\n",
       "      <td>NV Las Vegas - Gowan IC</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Q3'25</td>\n",
       "      <td>NC Concord IC</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>Q2'25</td>\n",
       "      <td>NC Concord IC</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>Q2'25</td>\n",
       "      <td>VA Chesterfield IC</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>Q2'25</td>\n",
       "      <td>ND Fargo</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DATE_QUARTER QUARTER                 LOCATION JOB_FAMILY_GROUP  AVG_LEADERS  \\\n",
       "0   2025-01-01   Q1'25  NV Las Vegas - Gowan IC        Logistics          1.0   \n",
       "1   2025-07-01   Q3'25            NC Concord IC        Logistics          2.0   \n",
       "2   2025-04-01   Q2'25            NC Concord IC        Logistics          2.0   \n",
       "3   2025-04-01   Q2'25       VA Chesterfield IC   Reconditioning          4.0   \n",
       "4   2025-04-01   Q2'25                 ND Fargo            ADESA          1.0   \n",
       "\n",
       "   LEADER_HIRED  LEADER_TERMED  \n",
       "0           NaN            NaN  \n",
       "1           NaN            2.0  \n",
       "2           NaN            NaN  \n",
       "3           NaN            NaN  \n",
       "4           NaN            NaN  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leadership.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadership.rename(columns={'LOCATION':'Location','JOB_FAMILY_GROUP':'JobFamilyGroup','QUARTER':'Quarter'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=pd.merge(main_df,leadership[['Location','JobFamilyGroup','Quarter','AVG_LEADERS','LEADER_HIRED','LEADER_TERMED']],on=['Location','JobFamilyGroup','Quarter'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.rename(columns={'AVG_LEADERS':'Avg_Leaders', 'LEADER_HIRED':'Leader_Hired', 'LEADER_TERMED':'Leader_Termed'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overtime_snow = db_snowflake.execute(\"\"\"\n",
    "#     SELECT \n",
    "#         LOCATIONNAME as LOCATION\n",
    "#         ,DATE_TRUNC('quarter',DATE) AS DATE_QUARTER\n",
    "#         ,CASE\n",
    "#         WHEN DATE_QUARTER = '2025-01-01' THEN 'Q1''25'                                                                           \n",
    "#         WHEN DATE_QUARTER = '2025-04-01' THEN 'Q2''25'\n",
    "#         WHEN DATE_QUARTER = '2025-07-01' THEN 'Q3''25'\n",
    "#         WHEN DATE_QUARTER = '2025-10-01' THEN 'Q4''25'                                                                          \n",
    "#         END AS Quarter\n",
    "#         ,'Reconditioning' AS JOB_FAMILY_GROUP\n",
    "#         ,ROUND(SUM(OVERTIMEHOURS),0) as TOTAL_OVERTIME\n",
    "#     FROM PEOPLEOPS_SANDBOX.DEV.IC_OVERTIME_AVG_HOURS\n",
    "#     WHERE DATE>='2025-01-01'\n",
    "#     GROUP BY LOCATIONNAME,DATE_TRUNC('quarter',DATE);\n",
    "#                                      \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPDATE TO SNOWFLAKE VERSION TABLE [INVENTORY.PUBLIC.EXPECTED_VS_PAID_HOURS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E102068\\AppData\\Local\\Temp\\ipykernel_27340\\2992662510.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  overtime_sql = pd.read_sql_query(overtimequery, odbcconnops)\n"
     ]
    }
   ],
   "source": [
    "overtimequery = \"\"\"Select LocationName as LOCATION,\n",
    "DATETRUNC(QUARTER,Date) as DATE_QUARTER,\n",
    "CASE \n",
    " WHEN JobFamilyGroup like '%RECON%' Then 'Reconditioning'\n",
    " WHEN JobFamilyGroup like '%POST%' Then 'Post Production'\n",
    " ELSE NULL\n",
    " END\n",
    " AS JOB_FAMILY_GROUP\n",
    ",CASE\n",
    "         WHEN DATETRUNC(QUARTER,Date) = '2025-01-01' THEN 'Q1''25'                                                                           \n",
    "         WHEN DATETRUNC(QUARTER,Date) = '2025-04-01' THEN 'Q2''25'\n",
    "         WHEN DATETRUNC(QUARTER,Date) = '2025-07-01' THEN 'Q3''25'\n",
    "         WHEN DATETRUNC(QUARTER,Date) = '2025-10-01' THEN 'Q4''25'                                                                          \n",
    "         END AS QUARTER\n",
    ",ROUND(SUM(OvertimeHours),0) as TOTAL_OVERTIME \n",
    "from opsgroup.ic.ExpectedvsPaidHours\n",
    "WHERE JobFamilyGroup in ('RECONDITIONING','POST_PRODUCTION')\n",
    "AND Date >='2025-01-01'\n",
    "GROUP BY LocationName,DATETRUNC(QUARTER,Date),JobFamilyGroup\"\"\"\n",
    "\n",
    "\n",
    "overtime_sql = pd.read_sql_query(overtimequery, odbcconnops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LOCATION",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DATE_QUARTER",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "JOB_FAMILY_GROUP",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "QUARTER",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TOTAL_OVERTIME",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "cd20e087-20fb-4053-8dc7-80991f8390f7",
       "rows": [
        [
         "0",
         "TX Dallas - Hutchins",
         "2025-10-01",
         "Reconditioning",
         "Q4'25",
         "3753.0"
        ],
        [
         "1",
         "TX San Antonio IC",
         "2025-04-01",
         "Reconditioning",
         "Q2'25",
         "18579.0"
        ],
        [
         "2",
         "MO Kansas City",
         "2025-01-01",
         "Reconditioning",
         "Q1'25",
         "6620.0"
        ],
        [
         "3",
         "GA Atlanta - Fairburn",
         "2025-04-01",
         "Reconditioning",
         "Q2'25",
         "9205.0"
        ],
        [
         "4",
         "GA Winder IC",
         "2025-10-01",
         "Reconditioning",
         "Q4'25",
         "9715.0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>DATE_QUARTER</th>\n",
       "      <th>JOB_FAMILY_GROUP</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>TOTAL_OVERTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TX Dallas - Hutchins</td>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>Q4'25</td>\n",
       "      <td>3753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TX San Antonio IC</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>Q2'25</td>\n",
       "      <td>18579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MO Kansas City</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>Q1'25</td>\n",
       "      <td>6620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GA Atlanta - Fairburn</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>Q2'25</td>\n",
       "      <td>9205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA Winder IC</td>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>Reconditioning</td>\n",
       "      <td>Q4'25</td>\n",
       "      <td>9715.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LOCATION DATE_QUARTER JOB_FAMILY_GROUP QUARTER  TOTAL_OVERTIME\n",
       "0   TX Dallas - Hutchins   2025-10-01   Reconditioning   Q4'25          3753.0\n",
       "1      TX San Antonio IC   2025-04-01   Reconditioning   Q2'25         18579.0\n",
       "2         MO Kansas City   2025-01-01   Reconditioning   Q1'25          6620.0\n",
       "3  GA Atlanta - Fairburn   2025-04-01   Reconditioning   Q2'25          9205.0\n",
       "4           GA Winder IC   2025-10-01   Reconditioning   Q4'25          9715.0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overtime_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "overtime_snow = overtime_sql.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "overtime_snow.rename(columns={'LOCATION':'Location','JOB_FAMILY_GROUP':'JobFamilyGroup','QUARTER':'Quarter','TOTAL_OVERTIME':'Total_Overtime_hours_Quarter'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=pd.merge(main_df,overtime_snow[['Location','JobFamilyGroup','Quarter','Total_Overtime_hours_Quarter']],on=['Location','JobFamilyGroup','Quarter'],how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowflake - Main DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Table\n",
    "# db_snowflake_write.create_table('metrics',\n",
    "#                   {\n",
    "#                      'Location': ['VARCHAR(1000)'],\n",
    "#                      'Score': ['INT'],\n",
    "#                      'eSat Change': ['INT'], \n",
    "#                      'JobFamilyGroup': ['VARCHAR(1000)'],\n",
    "#                      'Quarter': ['VARCHAR(1000)'], \n",
    "#                      'Injuries': ['INT'],\n",
    "#                      'EmployeesPIPs_CARs': ['INT'],\n",
    "#                      'CARs': ['INT'],\n",
    "#                      'PIPs': ['INT'],\n",
    "#                      'PIPs & CARs': ['INT'],\n",
    "#                      'Terminations': ['INT'],\n",
    "#                      'Quaterly_Turnover': ['INT'],\n",
    "#                      'Turnover_Change':['INT'],\n",
    "#                      'Total_Employees': ['INT'],\n",
    "#                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_snowflake_write.drop_table('metrics')\n",
    "# db_snowflake_write.dump('metrics',main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading data chunk num: 1: 100%|| 2846/2846 [00:00<00:00, 3343.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inserting the main df\n",
    "# db_snowflake_write.insert('metrics',main_df,truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_snowflake_write.drop_table('main_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalised Df for ranking - Site risk 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_df=main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Select only the numeric columns in the DataFrame\n",
    "numeric_cols = normalised_df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "\n",
    "# Fit on the data\n",
    "scaler.fit(normalised_df[numeric_cols])\n",
    "\n",
    "\n",
    "# Transform the data. This will return a numpy array.\n",
    "scaled_data = scaler.transform(normalised_df[numeric_cols])\n",
    "\n",
    "\n",
    "# Create a DataFrame from the numpy array, and assign the original column names\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=numeric_cols)\n",
    "\n",
    "\n",
    "# Replace the numeric columns in the original DataFrame with the scaled values\n",
    "normalised_df[numeric_cols] = scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, fill NaN values with 0\n",
    "normalised_df = normalised_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_df['Siterisk_KPI'] =(normalised_df['Score']*30)\\\n",
    "                                +(normalised_df['Quaterly_Turnover']*30)\\\n",
    "                                +(normalised_df['Terminations']*15)\\\n",
    "                                +(normalised_df['Injuries']*10)\\\n",
    "                                +(normalised_df['PIPs & CARs']*15)                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Only Necessary Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df= pd.DataFrame()\n",
    "# Appending all the csv files into one df\n",
    "for file in overall_files:\n",
    "    df_temp=pd.read_csv(file)\n",
    "    df_temp['File']= file.split('_')[-1].split('.')[0]\n",
    "    df_temp['Quarter']=file.split('_')[-2]\n",
    "        # filename=file.split('_')[-1].split('.')[0]\n",
    "    overall_df=pd.concat([overall_df,df_temp],ignore_index=True)\n",
    "\n",
    "overall_df=overall_df.rename(columns={'Organization':'JobFamilyGroup'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall CostCentre Dataframe\n",
    "overall_costcentre_df= overall_df[overall_df['Manager Email'].isna() & overall_df['Location'].isna()]\n",
    "\n",
    "# Selecting only neccesary columns\n",
    "overall_costcentre_df= overall_costcentre_df.iloc[:,[0,5,6,10]].reset_index(drop=True)\n",
    "\n",
    "# Rename Scores \n",
    "overall_costcentre_df=overall_costcentre_df.rename(columns={overall_costcentre_df.columns[1]:'Score',overall_costcentre_df.columns[2]:'eSat Change'})\n",
    "overall_costcentre_df['Location']='All'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Location Df\n",
    "overall_locations_df = overall_df[overall_df['JobFamilyGroup'].isna() & overall_df['Manager Email'].isna()]\n",
    "\n",
    "# Selecting only neccesary columns\n",
    "overall_locations_df= overall_locations_df.iloc[:,[-2,5,6,-3]].reset_index(drop=True)\n",
    "\n",
    "# Rename Scores \n",
    "overall_locations_df=overall_locations_df.rename(columns={overall_locations_df.columns[1]:'Score',overall_locations_df.columns[2]:'eSat Change'})\n",
    "overall_locations_df['JobFamilyGroup']='All'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Manager Df\n",
    "overall_managers_df = overall_df[overall_df['JobFamilyGroup'].isna() & overall_df['Location'].isna()]\n",
    "\n",
    "# Selecting only neccesary columns\n",
    "overall_managers_df= overall_managers_df.iloc[:,[-1,5,6,-3]].reset_index(drop=True)\n",
    "\n",
    "# Rename Scores \n",
    "overall_managers_df=overall_managers_df.rename(columns={overall_managers_df.columns[1]:'Score',overall_managers_df.columns[2]:'eSat Change'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_managers_sql= db_conn.execute(\"\"\"\n",
    "\n",
    "SELECT \n",
    "\tdistinct Manager1_Name as Manager,\n",
    "\tManager1_Level as ManagerLevel,\n",
    "    JobFamilyGroup,\n",
    "    Location,\n",
    "    count(*) as Employees\n",
    "FROM \n",
    "    PeopleOps.workday.tblEmployee\n",
    "WHERE \n",
    "    ActiveStatus = 1\n",
    "    AND SSIS_IsDeleted = 0\n",
    "    AND EmployeeType = 'Regular'\n",
    "    AND JobProfile NOT like '%ADESA%'\n",
    "GROUP By\n",
    "\tManager1_Name,\n",
    "\tManager1_Level,\n",
    "\tJobFamilyGroup,\n",
    "    Location\n",
    "Order By \n",
    "\tEmployees desc,\n",
    "\tJobFamilyGroup,\n",
    "    Location\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "overall_adesa_managers_sql= db_conn.execute(\"\"\"\n",
    "\n",
    "SELECT \n",
    "\tdistinct Manager1_Name as Manager,\n",
    "\tManager1_Level as ManagerLevel,\n",
    "    'ADESA' as JobFamilyGroup,\n",
    "    Location,\n",
    "    count(*) as Employees\n",
    "FROM \n",
    "    PeopleOps.workday.tblEmployee\n",
    "WHERE \n",
    "    ActiveStatus = 1\n",
    "    AND SSIS_IsDeleted = 0\n",
    "    AND EmployeeType = 'Regular'\n",
    "\tAnd JobProfile like '%ADESA%'\n",
    "GROUP By\n",
    "\tManager1_Name,\n",
    "\tManager1_Level,\n",
    "\tJobFamilyGroup,\n",
    "    Location\n",
    "Order By \n",
    "\tEmployees desc,\n",
    "\tJobFamilyGroup,\n",
    "    Location\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat managers df\n",
    "overall_managers_sql=pd.concat([overall_managers_sql,overall_adesa_managers_sql])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the managers name\n",
    "overall_managers_df['ManagerName'] = overall_managers_df['Manager Email'].str.split(\"'\").str[0]\n",
    "\n",
    "# Striping any space for proper join\n",
    "overall_managers_df['Manager'] = overall_managers_df['ManagerName'].str.strip()\n",
    "overall_managers_sql['Manager'] = overall_managers_sql['Manager'].str.strip()\n",
    "# overall_adesa_managers_sql['Manager']=overall_adesa_managers_sql['Manager'].str.strip()\n",
    "\n",
    "# Striping in between\n",
    "overall_managers_df['Manager'] = overall_managers_df['ManagerName'].str.replace(\" \",\"\")\n",
    "overall_managers_sql['Manager'] = overall_managers_sql['Manager'].str.replace(\" \",\"\")\n",
    "# overall_adesa_managers_sql['Manager']=overall_adesa_managers_sql['Manager'].str.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining GLINT and SQL\n",
    "managers_df=pd.merge(overall_managers_df,overall_managers_sql,on='Manager',how='left')\n",
    "\n",
    "# Selecting only neccesary jobfamily\n",
    "managers_df=managers_df[managers_df['JobFamilyGroup'].isin(necessary_JobFamilyGroups)]\n",
    "\n",
    "# Selecting only neccesary columns\n",
    "managers_df=managers_df[['ManagerName','ManagerLevel','Score','eSat Change','Quarter','Location','JobFamilyGroup','Employees']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric\n",
    "managers_df['Score']=pd.to_numeric(managers_df['Score'],errors='coerce')\n",
    "managers_df['eSat Change']=pd.to_numeric(managers_df['eSat Change'],errors='coerce')\n",
    "\n",
    "# Fill NA\n",
    "managers_df=managers_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowflake - Managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Create Table\n",
    "# db_snowflake_write.create_table('managers',\n",
    "#                   {\n",
    "#                      'ManagerName': ['VARCHAR(1000)'],\n",
    "#                      'ManagerLevel': ['VARCHAR(1000)'],\n",
    "#                      'Score': ['INT'],\n",
    "#                      'eSat Change': ['INT'],\n",
    "#                      'Quarter': ['VARCHAR(1000)'], \n",
    "#                      'Location': ['VARCHAR(1000)'], \n",
    "#                      'JobFamilyGroup': ['VARCHAR(1000)'],\n",
    "#                      'Employees': ['VARCHAR(1000)']\n",
    "#                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_snowflake_write.insert('managers',managers_df,truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overal Emp- CostCentres -(N/A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pulling All Locations,Costcentres Required and Total EMployees\n",
    "\n",
    "# overall_emp_costcentre_df= db_snowflake.execute(\"\"\"\n",
    "\n",
    "# SELECT JOB_FAMILY_GROUP as CostCentre, count(*) as TotalEmployees\n",
    "# from shared.dw.dim_employee\n",
    "# where JOB_FAMILY_GROUP in ('RECONDITIONING','MARKET_OPERATIONS','REGULATORY_OPERATIONS','LOGISTICS','WHOLESALE_OPERATIONS')\n",
    "# AND (is_employee_active='True' or  is_on_loa='True')\n",
    "# group by JOB_FAMILY_GROUP\n",
    "# order by TotalEmployees desc;\n",
    "\n",
    "# \"\"\")\n",
    "\n",
    "# # Pulling all Locations, Total Emp for ADESA - due to many misconsistencies with data\n",
    "\n",
    "# overall_ADESAemp_df= db_snowflake.execute(\"\"\"\n",
    "\n",
    "# SELECT 'ADESA' as CostCentre,count(*) as TotalEmployees\n",
    "# from shared.dw.dim_employee\n",
    "# where JOB_PROFILE like ('%ADESA%')\n",
    "# and is_employee_active='True' or  is_on_loa='True';\n",
    "\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combining the overall employee df\n",
    "# overall_emp_costcentre_df= pd.concat([overall_emp_costcentre_df,overall_ADESAemp_df])\n",
    "\n",
    "# # Clearing names\n",
    "# overall_emp_costcentre_df=overall_emp_costcentre_df.rename(columns={'COSTCENTRE':'CostCentre','TOTALEMPLOYEES':'TotalEmployees'})\n",
    "\n",
    "# # Rename Coscentre names\n",
    "# overall_emp_costcentre_df['CostCentre']=overall_emp_costcentre_df['CostCentre'].replace({'RECONDITIONING':'Reconditioning',\n",
    "#                                        'MARKET_OPERATIONS':'Market Operations',\n",
    "#                                        'REGULATORY_OPERATIONS':'Regulatory Operations',\n",
    "#                                        'LOGISTICS':'Logistics',\n",
    "#                                        'WHOLESALE_OPERATIONS':'Wholesale Operations'})\n",
    "\n",
    "# # Filtring only for SiteRisk Costcentres\n",
    "# overall_emp_costcentre_df=overall_emp_costcentre_df[overall_emp_costcentre_df['CostCentre'].isin(SiteRisk_CostCentres)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Emp - Locations - (N/A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_emp_locations_df= db_snowflake.execute(\"\"\"\n",
    "\n",
    "# SELECT LOCATION_NAME,count(*) as TotalEmployees\n",
    "# from shared.dw.dim_employee\n",
    "# where (JOB_FAMILY_GROUP in ('RECONDITIONING','MARKET_OPERATIONS','REGULATORY_OPERATIONS','LOGISTICS','WHOLESALE_OPERATIONS')\n",
    "# AND (is_employee_active='True' or  is_on_loa='True'))\n",
    "# OR (JOB_PROFILE like ('%ADESA%')) --ADESA Locations\n",
    "# group by LOCATION_NAME\n",
    "# order by TotalEmployees desc;\n",
    "\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clearing names\n",
    "# overall_emp_locations_df=overall_emp_locations_df.rename(columns={'LOCATION_NAME':'Location','TOTALEMPLOYEES':'TotalEmployees'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Locations/CostCentre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merging Total employees into overall locations/costcentre\n",
    "\n",
    "# overall_locations_df= pd.merge(overall_locations_df,overall_emp_locations_df, on='Location',how='left')\n",
    "\n",
    "# overall_costcentre_df= pd.merge(overall_costcentre_df,overall_emp_costcentre_df, on='CostCentre', how='left')\n",
    "\n",
    "# # Filtering out only for specific costcentre\n",
    "\n",
    "# overall_costcentre_df=overall_costcentre_df[overall_costcentre_df['CostCentre'].isin(SiteRisk_CostCentres)]\n",
    "# print(main_df[main_df['CostCentre']=='ADESA']['TotalEmployees'].sum())\n",
    "\n",
    "# # Overall DF\n",
    "\n",
    "# overall_main_df = pd.concat([overall_locations_df,overall_costcentre_df])\n",
    "\n",
    "# # # Convert 'Score' column to numeric, errors='coerce' will replace non-numeric values with NaN\n",
    "# # overall_main_df['Score'] = pd.to_numeric(overall_main_df['Score'], errors='coerce')\n",
    "# # overall_main_df['eSat Change'] = pd.to_numeric(overall_main_df['eSat Change'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation Bot and Webscraping (N/A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import selenium\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make sure website is open after run\n",
    "# options = Options()\n",
    "# options.add_experimental_option(\"detach\",True)\n",
    "\n",
    "# # Add driver\n",
    "# driver= webdriver.Chrome(service=Service(ChromeDriverManager().install()),options=options)\n",
    "# #driver.get(\"https://app.us1.glintinc.com/carvana/dashboard\")\n",
    "# driver.get(\"https://www.techwithtim.net/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Logic / Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdHoc\n",
    "# last_quater_performance_sql_df= db_conn.execute(\"\"\"\n",
    "\n",
    "# Select * FROM PeopleOps.workday.FactEmployeeReviews\n",
    "# WHERE ReviewStartDate >= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, '{date_today}') - 1, 0)\n",
    "# AND ReviewStartDate < DATEADD(QUARTER, DATEDIFF(QUARTER, 0, '{date_today}'), 0) \n",
    "# AND Status in ('In Process','Successfully Completed','Rescinded') \n",
    "# AND ReviewCategory in ('Corrective Action','Performance Improvement Plan')\n",
    "\n",
    "# \"\"\")\n",
    "\n",
    "# not_in_df = last_quater_performance_sql_df[~last_quater_performance_sql_df['EmployeeId'].isin(performance_sql_df['EmployeeId'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD Pips/CARs Logic\n",
    "\n",
    "# # PIPs and CARs Segmentation\n",
    "# pips_performance  = performance_sql_df[performance_sql_df['ReviewCategory']=='Performance Improvement Plan']\n",
    "# pips_performance= pips_performance.iloc[:,[0,1,-2,-1]]\n",
    "\n",
    "\n",
    "# cars_performance = performance_sql_df[performance_sql_df['ReviewCategory']=='Corrective Action']\n",
    "# cars_performance = cars_performance.iloc[:,[0,1,-2,-1]]\n",
    "# pips_performancecheck=pips_performance.groupby(['ReviewCategory','Location','Quarter']).agg('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL CSV PULL METHOD\n",
    "# # Files to pull location demographic csv\n",
    "# subdirectory_path=os.path.join(\"Glint Reports\",\"Q1'24\",\"Overall\")\n",
    "\n",
    "# # Level 1 csv files\n",
    "# overall_files= glob.glob(os.path.join(subdirectory_path, \"*.csv\"))\n",
    "\n",
    "\n",
    "# # Managers dataframe and selecting only imp columns\n",
    "# Managers_df= pd.read_csv(\"Glint Reports\\Q1'24\\Overall\\glint_report_Q1'24_Managers.csv\")\n",
    "# Managers_df['Quarter']= \n",
    "# Managers_df=Managers_df.iloc[:,[0,5,6]]\n",
    "\n",
    "# # CostCentres dataframe and selecting only imp columns\n",
    "# overall_costcentre_df= pd.read_csv(\"Glint Reports\\Q1'24\\Overall\\glint_report_Q1'24_CostCentres.csv\")\n",
    "# overall_costcentre_df= overall_costcentre_df.iloc[:,[0,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD Injury Logic\n",
    "\n",
    "# # Fetching Total Employees to calculate ratio excluding ADESA employee count becaus of ADESA coscentre and the original costcentre\n",
    "# Total_employees= db_conn.execute(\"\"\"\n",
    "\n",
    "# SELECT Count(*) as TotalEmployees ,JobFamilyGroup as CostCentre, Location \n",
    "# FROM [PeopleOps].[workday].[tblEmployee] \n",
    "# WHERE WorkerStatus In ('Active','On Leave') \n",
    "# AND Company NOT LIKE '%ADESA%' \n",
    "# GROUP BY JobFamilyGroup,Location \n",
    "# ORDER BY JobFamilyGroup,Location\n",
    "\n",
    "# \"\"\")\n",
    "\n",
    "# Total_employees_Overall= db_conn.execute(\"\"\"\n",
    "\n",
    "# SELECT Count(*) as TotalEmployees, Location \n",
    "# FROM [PeopleOps].[workday].[tblEmployee] \n",
    "# WHERE WorkerStatus In ('Active','On Leave') \n",
    "# AND Company NOT LIKE '%ADESA%' \n",
    "# AND JobFamilyGroup NOT LIKE '%ADESA%'\n",
    "# GROUP BY Location \n",
    "# ORDER BY TotalEmployees desc,Location\n",
    "\n",
    "# \"\"\")\n",
    "\n",
    "# # Merging with total employees\n",
    "# injury_df= pd.merge(injury_df,Total_employees, how='left', on=['Location','CostCentre'])\n",
    "\n",
    "# # Injuries across all locations\n",
    "# injury_all_df= injury_df[['Location','Quarter','Injuries']]\n",
    "# injury_all_df = injury_all_df.groupby(['Location','Quarter']).agg('sum').reset_index()\n",
    "# injury_all_df= pd.merge(injury_all_df,Total_employees_Overall, how='left', on=['Location'])\n",
    "# injury_all_df['CostCentre']='LocationsAll'\n",
    "# # Join Injury Data\n",
    "# injury_df=pd.concat([injury_df,injury_all_df])\n",
    "\n",
    "# # Calculating the ratio\n",
    "# injury_df['Injury Percentage']= round((injury_df['Injuries']/injury_df['TotalEmployees'])*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs={}\n",
    "# for file in files:\n",
    "#     # Define the file name\n",
    "#     file_name = pd.Series(file)\n",
    "#     # file_name = file.split('/')[-1].split('.')[0]\n",
    "\n",
    "#     # Use str.extract to capture the string from \"Q\" to just before \".csv\"\n",
    "#     captured_string = file_name.str.extract('(Q.*)(?=\\.csv)', expand=False)[0]\n",
    "\n",
    "#     # Df \n",
    "#     dfs[captured_string]=pd.read_csv(file)\n",
    "\n",
    "\n",
    "# # for i, df_name in enumerate(dfs.keys(), start=1):\n",
    "# #     globals()[f'df{i}'] = dfs[df_name]\n",
    "\n",
    "# for key, value in dfs.items():\n",
    "#     globals()[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = fetch_california_housing()\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "target = pd.DataFrame(data.target, columns=[\"MedHouseVal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "Y = target[\"MedHouseVal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(Y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_std = sm.OLS(Y, sm.add_constant(X_std)).fit()\n",
    "print(model_std.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_sq = np.square(model_std.params[1:])\n",
    "sum_coef_sq = np.sum(coef_sq)\n",
    "contributions = coef_sq / sum_coef_sq\n",
    "print(contributions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
